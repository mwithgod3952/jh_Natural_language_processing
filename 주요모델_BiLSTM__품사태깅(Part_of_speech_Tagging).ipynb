{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "주요모델_BiLSTM__품사태깅(Part_of_speech_Tagging)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNF409f3EOygeABywLWPcXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwithgod3952/jh_Natural_language_processing/blob/main/%EC%A3%BC%EC%9A%94%EB%AA%A8%EB%8D%B8_BiLSTM__%ED%92%88%EC%82%AC%ED%83%9C%EA%B9%85(Part_of_speech_Tagging).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1xdig0U15o7"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkJ6QJHe33hc",
        "outputId": "5ef84d07-51b6-45eb-95fa-6585ddca6f2c"
      },
      "source": [
        "nltk.download('treebank')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbsN3syy3NMr",
        "outputId": "405ad0be-227e-41de-baba-d7ca7f5c6eba"
      },
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "print(tagged_sentences)\n",
        "print('='*31)\n",
        "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]\n",
            "===============================\n",
            "품사 태깅이 된 문장 개수:  3914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQYzXnqf3tRr"
      },
      "source": [
        "***위, 기존 정보를 기준으로 단어에 해당하는 부분과, 품사에 해당하는 부분을 나누어 학습시킬 필요가 있다.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnQD9Hdy9jVD",
        "outputId": "d158eb06-3c0f-480b-fd0f-8e1886e4e867"
      },
      "source": [
        "# 각 문장에 대한 태깅정보가 리스트 단위로 저장되어 있음\n",
        "tagged_sentences[0], tagged_sentences[1] "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Pierre', 'NNP'),\n",
              "  ('Vinken', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('61', 'CD'),\n",
              "  ('years', 'NNS'),\n",
              "  ('old', 'JJ'),\n",
              "  (',', ','),\n",
              "  ('will', 'MD'),\n",
              "  ('join', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('board', 'NN'),\n",
              "  ('as', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('nonexecutive', 'JJ'),\n",
              "  ('director', 'NN'),\n",
              "  ('Nov.', 'NNP'),\n",
              "  ('29', 'CD'),\n",
              "  ('.', '.')],\n",
              " [('Mr.', 'NNP'),\n",
              "  ('Vinken', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('chairman', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('Elsevier', 'NNP'),\n",
              "  ('N.V.', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('the', 'DT'),\n",
              "  ('Dutch', 'NNP'),\n",
              "  ('publishing', 'VBG'),\n",
              "  ('group', 'NN'),\n",
              "  ('.', '.')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P47VvdMI4xph"
      },
      "source": [
        "sentences, pos_tags = [], [] \n",
        "\n",
        "for sentence in tagged_sentences:\n",
        "  snt, tag_info = zip(*sentence)\n",
        "  sentences.append(list(snt)) \n",
        "  pos_tags.append(list(tag_info))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "EZiR8EC86B83",
        "outputId": "c1cb3acf-d823-44df-af94-735dd79efbe6"
      },
      "source": [
        "plt.hist([len(X) for X in sentences], bins = 100)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o260TiiK6xRm",
        "outputId": "8b0fc679-d563-4cf8-cad4-fed49077d369"
      },
      "source": [
        "print('샘플의 최대길이 확인 : ', max((len(s) for s in sentences)))\n",
        "print('샘플의 평균길이 : ', sum(map(len, sentences)) / len(sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대길이 확인 :  271\n",
            "샘플의 평균길이 :  25.722023505365357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjdaP2Re60KZ"
      },
      "source": [
        "def tokenize(samples):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(samples)\n",
        "  return tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve3jdQe48exZ"
      },
      "source": [
        "하단이, 모델에 fitting되는 첫번째 단계이며, 우리는 모델 학습을 우해 두개의 모델을 필요로 한다는 것이 중요점인데, 문장의 요소에 관하여 그리고, 이의 구분자의 레이블 정보에 관하여 학습에 활용하도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA8TcMpp8WgV"
      },
      "source": [
        "src_tokenizer = tokenize(sentences)\n",
        "tar_tokenizer = tokenize(pos_tags)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg3cigR19eHS",
        "outputId": "c9523724-230d-4a4f-bcf6-a93adeaacdc1"
      },
      "source": [
        "# 통상 빈도수에 기준하여 만들어진 인덱스는 전체 문장 구성에 대한 단어의 인덱스를 저장하고 있으면 페딩 정보를 고려하여 +1를 vocab size로 정의\n",
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 11388\n",
            "태깅 정보 집합의 크기 : 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhBLRy_u-S4m"
      },
      "source": [
        "# 정수인코딩 시행\n",
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(pos_tags)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy2WSQck-oDc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def Structure_df(snetence_num, taged_num): \n",
        "  Structure_check = pd.DataFrame()\n",
        "  Structure_check['ori_ste'] = sentences[snetence_num]\n",
        "  Structure_check['encoded'] = X_train[taged_num]\n",
        "  return Structure_check  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "gdClmDnL_x9f",
        "outputId": "32f054f5-28b0-4b59-f2a6-a62c6ca477b4"
      },
      "source": [
        "Structure_df(2,2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ori_ste</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rudolph</td>\n",
              "      <td>2917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Agnew</td>\n",
              "      <td>5603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>1136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>years</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>old</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>and</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>former</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>chairman</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>of</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Consolidated</td>\n",
              "      <td>3747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Gold</td>\n",
              "      <td>1046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Fields</td>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PLC</td>\n",
              "      <td>893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>was</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>named</td>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>*-1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>a</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>nonexecutive</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>director</td>\n",
              "      <td>332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>of</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>this</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>British</td>\n",
              "      <td>1047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>industrial</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>conglomerate</td>\n",
              "      <td>2918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ori_ste  encoded\n",
              "0        Rudolph     2917\n",
              "1          Agnew     5603\n",
              "2              ,        1\n",
              "3             55     1136\n",
              "4          years       86\n",
              "5            old      331\n",
              "6            and        8\n",
              "7         former      602\n",
              "8       chairman      177\n",
              "9             of        4\n",
              "10  Consolidated     3747\n",
              "11          Gold     1046\n",
              "12        Fields      892\n",
              "13           PLC      893\n",
              "14             ,        1\n",
              "15           was       34\n",
              "16         named      483\n",
              "17           *-1        9\n",
              "18             a        6\n",
              "19  nonexecutive     2025\n",
              "20      director      332\n",
              "21            of        4\n",
              "22          this       51\n",
              "23       British     1047\n",
              "24    industrial      435\n",
              "25  conglomerate     2918\n",
              "26             .        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmLOCHST_4ts"
      },
      "source": [
        "# 테깅\n",
        "\n",
        "max_len = 150\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OfZPuyHAfeN"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymhliaOP3LYH"
      },
      "source": [
        "***One-Hot-Encoding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn-4BYOT20oj"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9DtCXPnAuEw"
      },
      "source": [
        "***Creating POS Tagger w, Bi-LSTM*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXx_6RX0BRKR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBzeUTsaEC_e"
      },
      "source": [
        "***Embeddings***\n",
        "\n",
        "    - nput_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "    - output_dim: Integer. Dimension of the dense embedding.\n",
        "    - embeddings_initializer: Initializer for the embeddings matrix (see keras.initializers).\n",
        "    - embeddings_regularizer: Regularizer function applied to the embeddings matrix (see keras.regularizers).\n",
        "    - embeddings_constraint: Constraint function applied to the embeddings matrix (see keras.constraints).\n",
        "    - mask_zero: Boolean, whether or not the input value 0 is a special \"padding\" value that should be masked out. This is useful when using recurrent layers which may take variable length input. If this is True, then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).\n",
        "    - input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6nkBVEBmVg"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "                              # 256 >> units: Positive integer, dimensionality of the output space. / return_sequences=True >> many_to_many 구현\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "                              # tag_size = len(tar_tokenizer.word_index) + 1 \n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])                                                      "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlvidaVjqmCW",
        "outputId": "d8e82585-4374-405b-ba78-f27c84493522"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=6,  validation_data=(X_test, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "25/25 [==============================] - 41s 148ms/step - loss: 0.6180 - accuracy: 0.1258 - val_loss: 0.5079 - val_accuracy: 0.1648\n",
            "Epoch 2/6\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4963 - accuracy: 0.1929 - val_loss: 0.4621 - val_accuracy: 0.3374\n",
            "Epoch 3/6\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4367 - accuracy: 0.3887 - val_loss: 0.3278 - val_accuracy: 0.5035\n",
            "Epoch 4/6\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.2875 - accuracy: 0.5742 - val_loss: 0.1857 - val_accuracy: 0.7396\n",
            "Epoch 5/6\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.1536 - accuracy: 0.7939 - val_loss: 0.1000 - val_accuracy: 0.8663\n",
            "Epoch 6/6\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.0756 - accuracy: 0.9062 - val_loss: 0.0657 - val_accuracy: 0.9080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f4dc76c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J8nhdyN2b1s",
        "outputId": "462951bc-d867-462f-c590-c8793f0211ea"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.9080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06570595502853394, 0.9080430865287781]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utuav1tC3vZt",
        "outputId": "d8721b69-6a4a-4808-d238-b874493f2151"
      },
      "source": [
        "print(\"테스트 정확도: \", (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.9080\n",
            "테스트 정확도:  0.9080430865287781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFwz6dp36Oa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oONs1pep4KVL"
      },
      "source": [
        "***Model_Test***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWsDd6Mx6YGf",
        "outputId": "4a6eab40-6b99-4406-a171-1b9a329a7281"
      },
      "source": [
        "y_test[10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mM4DZby4vKo"
      },
      "source": [
        "index_to_word=src_tokenizer.index_word\n",
        "index_to_tag=tar_tokenizer.index_word\n",
        "\n",
        "i=10\n",
        "y_predicted = model.predict(np.array([X_test[i]]))\n",
        "y_predicted = np.argmax(y_predicted, axis=-1)\n",
        "\n",
        "true = np.argmax(y_test[i], -1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKKabl-6Jyr"
      },
      "source": [
        "***위의 테스트 과정을 플이하면 다음과 같다***\n",
        "\n",
        "  - 내가 예하고자 하는 문장에 대하여, 우선 model.fit을 진행한다.\n",
        "          단. 텍스트와 관련한 전처리가 완료된 상태여야 하는데, 위의 과정은 본래 내가 지정해 둔 y_test를 그대로 실행하는 경우이기의 별도의 전처리 과정은 포함되지 않았다.\n",
        "  - 위의 값 즉 predicted 된 원핫인코딩 값을 다시 정수 인코딩 형태로 바꾼다.\n",
        "  - 실제값에 대한 것도 마찬가지로 정수 인코딩으로 바꾼다.\n",
        "\n",
        "  즉, 테스트 데이터를 통한 모델의 결과값과, 테스트로 사용된 데이터 모두 정수 인코딩 형태로 바꾸어 가지고 있는 상태이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHnIznY_4NEy",
        "outputId": "feac9e8d-bb38-43a9-92c8-17ee6a9af133"
      },
      "source": [
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in               : IN      IN\n",
            "addition         : NN      NN\n",
            ",                : ,       ,\n",
            "buick            : NNP     NNP\n",
            "is               : VBZ     VBZ\n",
            "a                : DT      DT\n",
            "relatively       : RB      RB\n",
            "respected        : VBN     VBN\n",
            "nameplate        : NN      NN\n",
            "among            : IN      IN\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "card             : NN      NN\n",
            "holders          : NNS     NNS\n",
            ",                : ,       ,\n",
            "says             : VBZ     VBZ\n",
            "0                : -NONE-  -NONE-\n",
            "*t*-1            : -NONE-  -NONE-\n",
            "an               : DT      DT\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "spokeswoman      : NN      NN\n",
            ".                : .       .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}