{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "챗봇_Demo",
      "provenance": [],
      "collapsed_sections": [
        "1IvmxWogjU_h",
        "P5DuNGiHyNJJ",
        "XSU70wJRQ-hb"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNr3r8FlO5U5O3b0UIPIfUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwithgod3952/jh_Natural_language_processing/blob/main/%EC%B1%97%EB%B4%87_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nCv7-rGJEga"
      },
      "source": [
        "***의도***\n",
        "-\t투자정보\n",
        "-\t가격 \n",
        "-\t거래량 \n",
        "-\t관련주\n",
        "\n",
        "***개체명***\n",
        "\n",
        "-\tSTO : 회사(주식)명\n",
        "- MAR : 시장(비트코인, 코스피 코스닥 등...)\n",
        "-\tDAT : 날짜(오늘, 어제)\n",
        "-\tPUR : 질문의 목적\n",
        "- VEL\n",
        "-\tYEA\n",
        "-\tMON\n",
        "-\tDAY\n",
        "- WEK\n",
        "-\t검색에 반영할 조건\n",
        "  *\tIND:산업\n",
        "  *\tACT:엑션\n",
        "-\tABN: 분석목적(이상치 탐색, 분석결과 제시)\n",
        "- EMO: 감정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IvmxWogjU_h"
      },
      "source": [
        "# 설치구간"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLexIq6YekvY",
        "outputId": "767571f7-afd7-46ed-b9be-ceb94650ba57"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh\n",
        "!git clone https://github.com/entelecheia/eKoNLPy.git\n",
        "%cd eKoNLPy/\n",
        "!python setup.py install\n",
        "!pip install -U finance-datareader"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ib4le8hi\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-ib4le8hi\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=abea54a73fcbf1d7981e70f6c4eafa47d789e2f1d43e9c311d95dfe7df28ee5a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dga70l_e/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 22.6MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-04-22 14:09:42--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=UUBqMH3r9%2BEfPXNpGMRszOhUNUE%3D&Expires=1619102382&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-04-22 14:09:42--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=UUBqMH3r9%2BEfPXNpGMRszOhUNUE%3D&Expires=1619102382&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.74.44\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.74.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  6.52MB/s    in 0.2s    \n",
            "\n",
            "2021-04-22 14:09:43 (6.52 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-04-22 14:11:21--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c2:513, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ggvsOSAqBgxyEMfzVz6y%2BrMBxwg%3D&Expires=1619101747&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-04-22 14:11:22--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ggvsOSAqBgxyEMfzVz6y%2BrMBxwg%3D&Expires=1619101747&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.9.195\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.9.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  64.3MB/s    in 0.7s    \n",
            "\n",
            "2021-04-22 14:11:23 (64.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "Cloning into 'eKoNLPy'...\n",
            "remote: Enumerating objects: 3590, done.\u001b[K\n",
            "remote: Total 3590 (delta 0), reused 0 (delta 0), pack-reused 3590\u001b[K\n",
            "Receiving objects: 100% (3590/3590), 73.30 MiB | 22.51 MiB/s, done.\n",
            "Resolving deltas: 100% (2618/2618), done.\n",
            "/content/Mecab-ko-for-Google-Colab/eKoNLPy\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating eKoNLPy.egg-info\n",
            "writing eKoNLPy.egg-info/PKG-INFO\n",
            "writing dependency_links to eKoNLPy.egg-info/dependency_links.txt\n",
            "writing requirements to eKoNLPy.egg-info/requires.txt\n",
            "writing top-level names to eKoNLPy.egg-info/top_level.txt\n",
            "writing manifest file 'eKoNLPy.egg-info/SOURCES.txt'\n",
            "writing manifest file 'eKoNLPy.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ekonlpy\n",
            "copying ekonlpy/utils.py -> build/lib/ekonlpy\n",
            "copying ekonlpy/__init__.py -> build/lib/ekonlpy\n",
            "copying ekonlpy/dictionary.py -> build/lib/ekonlpy\n",
            "creating build/lib/ekonlpy/etag\n",
            "copying ekonlpy/etag/_template.py -> build/lib/ekonlpy/etag\n",
            "copying ekonlpy/etag/__init__.py -> build/lib/ekonlpy/etag\n",
            "creating build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/utils.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/base.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/kosac.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/__init__.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/euko.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/hiv4.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/lm.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/mpko.py -> build/lib/ekonlpy/sentiment\n",
            "copying ekonlpy/sentiment/mpck.py -> build/lib/ekonlpy/sentiment\n",
            "creating build/lib/ekonlpy/data\n",
            "copying ekonlpy/data/tagset.py -> build/lib/ekonlpy/data\n",
            "copying ekonlpy/data/__init__.py -> build/lib/ekonlpy/data\n",
            "creating build/lib/ekonlpy/tag\n",
            "copying ekonlpy/tag/__init__.py -> build/lib/ekonlpy/tag\n",
            "copying ekonlpy/tag/_mecab.py -> build/lib/ekonlpy/tag\n",
            "copying ekonlpy/tag/_postprocess.py -> build/lib/ekonlpy/tag\n",
            "creating build/lib/ekonlpy/topic\n",
            "copying ekonlpy/topic/mptk.py -> build/lib/ekonlpy/topic\n",
            "copying ekonlpy/topic/__init__.py -> build/lib/ekonlpy/topic\n",
            "creating build/lib/ekonlpy/data/model\n",
            "copying ekonlpy/data/model/mp_topic_titles-k36.txt -> build/lib/ekonlpy/data/model\n",
            "creating build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/Geographic.txt -> build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/Generic.txt -> build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/Currencies.txt -> build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/DatesandNumbers.txt -> build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/Names.txt -> build/lib/ekonlpy/data/lexicon\n",
            "creating build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/INSTITUTION.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/FOREIGN_TERMS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/STOPWORDS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/STOPWORDS_EN.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/INDUSTRY_TERMS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SYNONYM_PHRASES.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/GENERIC.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SYNONYM.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/ECON_PHRASES.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SYNONYM_VA.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/UNIT.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/NAMES.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/POLARITY_PHRASES.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/STOPWORDS_CUST.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/PROPER_NOUNS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/NOUNS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/COUNTRY.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SECTOR.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/CURRENCY.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/VERBS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/STOPWORDS_KOR.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/LEMMA.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SYNONYM_TERMS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/ADJECTIVES.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/ECON_TERMS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/ADVERBS.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/SYNONYM_MAG.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/dictionary/ENTITY.txt -> build/lib/ekonlpy/data/dictionary\n",
            "copying ekonlpy/data/lexicon/LM.csv -> build/lib/ekonlpy/data/lexicon\n",
            "copying ekonlpy/data/lexicon/HIV-4.csv -> build/lib/ekonlpy/data/lexicon\n",
            "creating build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_wordset.txt -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_vocab.txt -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "creating build/lib/ekonlpy/data/lexicon/kosac\n",
            "copying ekonlpy/data/lexicon/kosac/intensity.csv -> build/lib/ekonlpy/data/lexicon/kosac\n",
            "copying ekonlpy/data/lexicon/kosac/expressive-type.csv -> build/lib/ekonlpy/data/lexicon/kosac\n",
            "copying ekonlpy/data/lexicon/kosac/polarity.csv -> build/lib/ekonlpy/data/lexicon/kosac\n",
            "creating build/lib/ekonlpy/data/lexicon/euko\n",
            "copying ekonlpy/data/lexicon/euko/mp_uncertainty_lexicon_mkt.csv -> build/lib/ekonlpy/data/lexicon/euko\n",
            "copying ekonlpy/data/lexicon/euko/mp_uncertainty_lexicon_lex.csv -> build/lib/ekonlpy/data/lexicon/euko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt_n3.csv -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt_n7.csv -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt.csv -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_lex.csv -> build/lib/ekonlpy/data/lexicon/mpko\n",
            "copying ekonlpy/data/model/mp_corpus.dict -> build/lib/ekonlpy/data/model\n",
            "copying ekonlpy/data/model/mp_topic_model-k36.lda.expElogbeta.npy -> build/lib/ekonlpy/data/model\n",
            "copying ekonlpy/data/model/MPKC.nbc -> build/lib/ekonlpy/data/model\n",
            "copying ekonlpy/data/model/mp_topic_model-k36.lda -> build/lib/ekonlpy/data/model\n",
            "copying ekonlpy/data/model/mp_topic_model-k36.lda.state -> build/lib/ekonlpy/data/model\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/etag\n",
            "copying build/lib/ekonlpy/etag/_template.py -> build/bdist.linux-x86_64/egg/ekonlpy/etag\n",
            "copying build/lib/ekonlpy/etag/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy/etag\n",
            "copying build/lib/ekonlpy/utils.py -> build/bdist.linux-x86_64/egg/ekonlpy\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/utils.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/base.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/kosac.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/euko.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/hiv4.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/lm.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/mpko.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/sentiment/mpck.py -> build/bdist.linux-x86_64/egg/ekonlpy/sentiment\n",
            "copying build/lib/ekonlpy/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data\n",
            "copying build/lib/ekonlpy/data/tagset.py -> build/bdist.linux-x86_64/egg/ekonlpy/data\n",
            "copying build/lib/ekonlpy/data/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy/data\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/mp_corpus.dict -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/mp_topic_model-k36.lda.expElogbeta.npy -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/MPKC.nbc -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/mp_topic_model-k36.lda -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/mp_topic_model-k36.lda.state -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "copying build/lib/ekonlpy/data/model/mp_topic_titles-k36.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/model\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "copying build/lib/ekonlpy/data/lexicon/Geographic.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "copying build/lib/ekonlpy/data/lexicon/LM.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/kosac\n",
            "copying build/lib/ekonlpy/data/lexicon/kosac/intensity.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/kosac\n",
            "copying build/lib/ekonlpy/data/lexicon/kosac/expressive-type.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/kosac\n",
            "copying build/lib/ekonlpy/data/lexicon/kosac/polarity.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/kosac\n",
            "copying build/lib/ekonlpy/data/lexicon/Generic.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "copying build/lib/ekonlpy/data/lexicon/Currencies.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "copying build/lib/ekonlpy/data/lexicon/DatesandNumbers.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "copying build/lib/ekonlpy/data/lexicon/HIV-4.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/euko\n",
            "copying build/lib/ekonlpy/data/lexicon/euko/mp_uncertainty_lexicon_mkt.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/euko\n",
            "copying build/lib/ekonlpy/data/lexicon/euko/mp_uncertainty_lexicon_lex.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/euko\n",
            "copying build/lib/ekonlpy/data/lexicon/Names.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_wordset.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_vocab.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt_n3.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt_n7.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_mkt.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "copying build/lib/ekonlpy/data/lexicon/mpko/mp_polarity_lexicon_lex.csv -> build/bdist.linux-x86_64/egg/ekonlpy/data/lexicon/mpko\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/INSTITUTION.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/FOREIGN_TERMS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/STOPWORDS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/STOPWORDS_EN.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/INDUSTRY_TERMS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SYNONYM_PHRASES.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/GENERIC.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SYNONYM.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/ECON_PHRASES.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SYNONYM_VA.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/UNIT.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/NAMES.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/POLARITY_PHRASES.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/STOPWORDS_CUST.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/PROPER_NOUNS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/NOUNS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/COUNTRY.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SECTOR.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/CURRENCY.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/VERBS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/STOPWORDS_KOR.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/LEMMA.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SYNONYM_TERMS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/ADJECTIVES.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/ECON_TERMS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/ADVERBS.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/SYNONYM_MAG.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/data/dictionary/ENTITY.txt -> build/bdist.linux-x86_64/egg/ekonlpy/data/dictionary\n",
            "copying build/lib/ekonlpy/dictionary.py -> build/bdist.linux-x86_64/egg/ekonlpy\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/tag\n",
            "copying build/lib/ekonlpy/tag/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy/tag\n",
            "copying build/lib/ekonlpy/tag/_mecab.py -> build/bdist.linux-x86_64/egg/ekonlpy/tag\n",
            "copying build/lib/ekonlpy/tag/_postprocess.py -> build/bdist.linux-x86_64/egg/ekonlpy/tag\n",
            "creating build/bdist.linux-x86_64/egg/ekonlpy/topic\n",
            "copying build/lib/ekonlpy/topic/mptk.py -> build/bdist.linux-x86_64/egg/ekonlpy/topic\n",
            "copying build/lib/ekonlpy/topic/__init__.py -> build/bdist.linux-x86_64/egg/ekonlpy/topic\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/etag/_template.py to _template.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/etag/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/kosac.py to kosac.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/euko.py to euko.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/hiv4.py to hiv4.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/lm.py to lm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/mpko.py to mpko.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/sentiment/mpck.py to mpck.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/data/tagset.py to tagset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/data/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/dictionary.py to dictionary.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/tag/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/tag/_mecab.py to _mecab.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/tag/_postprocess.py to _postprocess.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/topic/mptk.py to mptk.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ekonlpy/topic/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying eKoNLPy.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying eKoNLPy.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying eKoNLPy.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying eKoNLPy.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying eKoNLPy.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "ekonlpy.__pycache__.utils.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/eKoNLPy-0.5.30-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing eKoNLPy-0.5.30-py3.7.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/eKoNLPy-0.5.30-py3.7.egg\n",
            "Extracting eKoNLPy-0.5.30-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding eKoNLPy 0.5.30 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/eKoNLPy-0.5.30-py3.7.egg\n",
            "Processing dependencies for eKoNLPy==0.5.30\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gensim==3.6.0\n",
            "Best match: gensim 3.6.0\n",
            "Adding gensim 3.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for nltk==3.2.5\n",
            "Best match: nltk 3.2.5\n",
            "Adding nltk 3.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for konlpy==0.5.2\n",
            "Best match: konlpy 0.5.2\n",
            "Adding konlpy 0.5.2 to easy-install.pth file\n",
            "Installing stream_daum script to /usr/local/bin\n",
            "Installing stream_dcinside script to /usr/local/bin\n",
            "Installing stream_google script to /usr/local/bin\n",
            "Installing stream_naver script to /usr/local/bin\n",
            "Installing stream_twitter script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for smart-open==5.0.0\n",
            "Best match: smart-open 5.0.0\n",
            "Adding smart-open 5.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for JPype1==1.2.1\n",
            "Best match: JPype1 1.2.1\n",
            "Adding JPype1 1.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for beautifulsoup4==4.6.0\n",
            "Best match: beautifulsoup4 4.6.0\n",
            "Adding beautifulsoup4 4.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for colorama==0.4.4\n",
            "Best match: colorama 0.4.4\n",
            "Adding colorama 0.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for lxml==4.2.6\n",
            "Best match: lxml 4.2.6\n",
            "Adding lxml 4.2.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tweepy==3.10.0\n",
            "Best match: tweepy 3.10.0\n",
            "Adding tweepy 3.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.0\n",
            "Best match: requests-oauthlib 1.3.0\n",
            "Adding requests-oauthlib 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PySocks==1.7.1\n",
            "Best match: PySocks 1.7.1\n",
            "Adding PySocks 1.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2020.12.5\n",
            "Best match: certifi 2020.12.5\n",
            "Adding certifi 2020.12.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.1.0\n",
            "Best match: oauthlib 3.1.0\n",
            "Adding oauthlib 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for eKoNLPy==0.5.30\n",
            "Collecting finance-datareader\n",
            "  Downloading https://files.pythonhosted.org/packages/83/5e/54306e72b5ff5d5ec6cc9f32cdf19602237f9bb70d64efcd527338388be3/finance_datareader-0.9.31-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (2.23.0)\n",
            "Collecting requests-file\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from requests-file->finance-datareader) (1.15.0)\n",
            "Installing collected packages: requests-file, finance-datareader\n",
            "Successfully installed finance-datareader-0.9.31 requests-file-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1kOHlS_igUP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5DuNGiHyNJJ"
      },
      "source": [
        "# 기본설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErlcmnX1JhXn",
        "outputId": "bc889546-0f75-4828-f65e-9abbf2e4666f"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "import io\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import quote\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from ekonlpy.tag import Mecab\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "!apt -qq -y install fonts-nanum\n",
        "\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The following packages were automatically installed and are no longer required:\n",
            "  r-cran-covr r-cran-crosstalk r-cran-dt r-cran-htmlwidgets r-cran-later\n",
            "  r-cran-lazyeval r-cran-promises r-cran-rex\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 161275 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Rh42FlYMHH",
        "outputId": "c471aba8-0d9f-431d-ef39-a7aed363cc20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkFOZfm_tmx0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IV6_qVcjcxZ"
      },
      "source": [
        "# 질문초안"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRFEpjFxWlY"
      },
      "source": [
        "### ***의도1 : 투자정보***\n",
        "\n",
        "  - 얻고자 하는 투자정보에 대해 웹 뉴스기사 검색을 기반으로 자료를 취합하여 제곡하고자 한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFCpqC2LhT_n"
      },
      "source": [
        "***투자정보 관련 질문 생성 단계***\n",
        "\n",
        "    - 아이디어 : 블로그 글 크롤링 및 활용\n",
        "    - 질문 관련 글 크롤링 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NbAGsARw4U6"
      },
      "source": [
        "###### ***주식커뮤니티 토론방 내용에서 흰트얻기***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlX7bzqRwpGY"
      },
      "source": [
        "# # 1-3 : \n",
        "# 출처 : https://www.stocker.kr/index.php?mid=discuss&page=1 (커뮤니티명 : STOCKER)\n",
        "\n",
        "def crawling_comment(pages = 3):\n",
        "  comment_df = pd.DataFrame(columns=('index', 'comment'))\n",
        "  idx = 0\n",
        "  for X in range(1, pages):\n",
        "    url = f'https://www.stocker.kr/index.php?mid=discuss&page={X}'\n",
        "    surf_url = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(surf_url, 'html.parser')\n",
        "    sentences = soup.find_all('span', {'class':'ed title-link'})\n",
        "    for sentence in range(len(sentences)):\n",
        "      s = re.sub(r'[.,!<>/=?\"\\':;~()]', '', str(sentences[sentence]))\n",
        "      cmt = re.sub('[a-zA-z]','',s)\n",
        "      comment_df.loc[idx] = [idx, cmt]\n",
        "      idx += 1\n",
        "  return comment_df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8gIbvjJwuBV"
      },
      "source": [
        "# 마지막 페이지가 18페이지\n",
        "comment_df = crawling_comment(pages=19)\n",
        "comment_df = comment_df.drop('index', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAg-xHSwyz2"
      },
      "source": [
        "comment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNyv-ASywyJi"
      },
      "source": [
        "from google.colab import files\n",
        "comment_df.to_excel('commnet_dataset.xlsx', index=False)\n",
        "files.download('commnet_dataset.xlsx')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZW55qHCxwjy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4hmhq8Xx1Nc"
      },
      "source": [
        "###### ***주식송목 크롤링***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVKHh5qke0O0"
      },
      "source": [
        "import FinanceDataReader as fdr\n",
        "\n",
        "df_krx = fdr.StockListing('KRX')\n",
        "stock_list = df_krx['Name'].tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-3STr5Lx4UF"
      },
      "source": [
        "###### ***질물생성_1 (의도 :  투자정보)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8c1_q-uaKnD"
      },
      "source": [
        "# 개체명 구성 : STO(주식명)\n",
        "\n",
        "name = stock_list \n",
        "\n",
        "markets = ['비트코인', '코스피', '코스닥']\n",
        "name.append(markets[0])\n",
        "name.append(markets[1])\n",
        "name.append(markets[2])\n",
        "\n",
        "def question_invest_info_1(list = name):\n",
        "  se_0 = []\n",
        "  for n in list:\n",
        "    s1 = n+' 투자관련 지식정보'\n",
        "    s2 = n+' 최근 이슈'\n",
        "    s3 = n+' 필수정보'\n",
        "    s4 = n+' 트렌트 탐색'\n",
        "    s5 = n+' 주식투자에 필요한 기사 알려줘'\n",
        "    s6 = n+' 주식에 필요한 내용 알려줘'\n",
        "    s7 = n+' 주식 관련 추천기사 알려줘'\n",
        "    s8 = n+' 추천기사'\n",
        "    s9 = n+' 추천뉴스'\n",
        "    s10 = n+' 트렌드'\n",
        "    s11 = n+' 트렌드 알려줘'\n",
        "    s12 = n+'를 분석해주세요'\n",
        "    s13 = n+' 분석해봐'\n",
        "    s14 = n+' 인기있는 기사'\n",
        "    s15 = n+'의 가장 핫한 이슈가 뭐야'\n",
        "    s16 = n+'의 반드시 알아야 할 내용'\n",
        "    s17 = n+' 트렌드 알려줘'\n",
        "    s18 = n+' 인기있는 기사'\n",
        "    s19 = n+'의 가장 핫한 이슈가 뭐야'\n",
        "    s20 = n+'의 반드시 알아야 할 내용'\n",
        "    s21 = n+' 소식'\n",
        "    s22 = n+' 소식요약'\n",
        "    s23 = n+'에 투자하기 위해 기업과 관련된 뉴스를 탐색해줄래'\n",
        "    s24 = n+'에 투자하려고 하는데 실적정보를 알려줄래'\n",
        "    s25 = n+'투자하는게 잘한 선택일까?'\n",
        "    s26 = n+'에 대해 니 생각은 어때?'\n",
        "    s27 = n+'주식 초보 기초정보'\n",
        "    se_0 = se_0+[s1, s2, s3, s4, s5, s6, s6, s7, s8, s9, s10, s11, s12, s13, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27]\n",
        "  return se_0\n",
        "\n",
        "# 개체명 구성 : MAR, VEL\n",
        "markets = ['비트코인', '코스피', '코스닥', '대형주', '중소형주', '중형주', '소형주']\n",
        "stock_status = ['공매도', '배당금']\n",
        "\n",
        "s_name = stock_status\n",
        "m_name = markets\n",
        "\n",
        "def question_invest_info_2(list_1 = m_name, list_2 = s_name):\n",
        "  se_1 = []\n",
        "  for n1 in list_1:\n",
        "    for n2 in list_2:\n",
        "        s1 = f'{n1}에서 {n2}현상이 지속될만한 금융상품 뉴스를 취합해줘'\n",
        "        s2 = f'{n1}에서 {n2} 예상되는 주식뉴스를 취합해줘'\n",
        "        s3 = f'{n1} {n2} 관련 뉴스 검색해줘'\n",
        "        s4 = f'{n1} {n2} 분위기좀 알려줘'\n",
        "        s5 = f'{n1} {n2} 계속 들썩거리니?'\n",
        "        s6 = f'{n1} {n2} 상황이 어때?'\n",
        "        se_1 = se_1+[s1, s2, s3, s5, s6]\n",
        "  return se_1\n",
        "\n",
        "# 개채명 구성 : MON, DAY, VEL\n",
        "volatility = ['상승', '하락', '정체', '급등']\n",
        "weeks = ['첫째주', '둘째주', '셋째주', '넷째주']\n",
        "\n",
        "def question_invest_info_3(list_1 = stock_list):\n",
        "  se_2 = []\n",
        "  for stock in range(len(list_1)):\n",
        "    name = list_1[stock]\n",
        "    for v in volatility:\n",
        "      s1 = f'{random.randint(1,12)}월 {random.randint(1,30)}일 {name} {v}관련 이슈 취합해줘'\n",
        "      # print(s1)\n",
        "      s2 = f'{random.randint(1,12)}월 {random.randint(1,30)}일 {name} {v}관련 자료'\n",
        "      # print(s2)\n",
        "      s3 = f'{random.randint(1,12)}월 {random.choice(weeks)} {name} {v}'\n",
        "      # print(s3)\n",
        "      se_2 = se_2+[s1, s2, s3]\n",
        "  return se_2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGUSQoggQQae"
      },
      "source": [
        "###### Mecab 사전추가(의도 : 투자정보)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7PQ1z0MsmKP"
      },
      "source": [
        "mecab = Mecab()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtWXLS8bybzL"
      },
      "source": [
        "for s in stock_list:\n",
        "  mecab.add_dictionary(s, 'NNG')\n",
        "for m in markets:\n",
        "  mecab.add_dictionary(m, 'NNG')\n",
        "for t in stock_status:\n",
        "  mecab.add_dictionary(t, 'NNG')\n",
        "for w in weeks:\n",
        "  mecab.add_dictionary(w, 'NNG')\n",
        "for v in volatility:\n",
        "  mecab.add_dictionary(v, 'NNG')\n",
        "# for S in Sector:\n",
        "#   mecab.add_dictionary(S, 'NNG')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwAV1Oee5_VK",
        "outputId": "1179a504-cf73-4d54-8719-fa60cc0687ac"
      },
      "source": [
        "cr_year = [X + '년' for X in [str(x) for x in list(range(1,11))]]\n",
        "print(cr_year)\n",
        "for y in cr_year:\n",
        "  mecab.add_dictionary(y, 'NNG')\n",
        "cr_month = [X + '월' for X in [str(x) for x in list(range(1,13))]]\n",
        "print(cr_month)\n",
        "for m in cr_month:\n",
        "  mecab.add_dictionary(m, 'NNG')\n",
        "cr_day = [X + '일' for X in [str(x) for x in list(range(1,32))]]\n",
        "print(cr_day)\n",
        "for d in cr_day:\n",
        "  mecab.add_dictionary(d, 'NNG')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1년', '2년', '3년', '4년', '5년', '6년', '7년', '8년', '9년', '10년']\n",
            "['1월', '2월', '3월', '4월', '5월', '6월', '7월', '8월', '9월', '10월', '11월', '12월']\n",
            "['1일', '2일', '3일', '4일', '5일', '6일', '7일', '8일', '9일', '10일', '11일', '12일', '13일', '14일', '15일', '16일', '17일', '18일', '19일', '20일', '21일', '22일', '23일', '24일', '25일', '26일', '27일', '28일', '29일', '30일', '31일']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iVO09YrS-8l"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ritdoA0oVR"
      },
      "source": [
        "###### 사전추가로 해결되지 않는 회사이름에 대한 개체명 인식 방법 모색_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuCB00Lx-xty"
      },
      "source": [
        "    - 문장 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K08e7_vXUdLV",
        "outputId": "f5bc9a6d-a227-4d93-c800-3ecaaf29e871"
      },
      "source": [
        "q_invest_1_sample = question_invest_info_1(list = ['3s'])\n",
        "\n",
        "samples_tokenized_invest_q1 = []\n",
        "for q in q_invest_1_sample:\n",
        "  samples_tokenized_invest_q1.append(mecab.morphs(q))\n",
        "\n",
        "remove_object_name_f_se1 = [X for sublist in samples_tokenized_invest_q1 for X in sublist if X != '3s']\n",
        "remove_object_name_f_se1[:10]  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['투자', '관련', '지식', '정보', '최근', '이슈', '필수', '정보', '트렌트', '탐색']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WanR214wsmOT"
      },
      "source": [
        "invest_info_1 = question_invest_info_1()\n",
        "\n",
        "tokenized_sequences = []\n",
        "label_sequences = []\n",
        "\n",
        "for sample in invest_info_1:\n",
        "  temp_sample = []\n",
        "  tokenized_sample = mecab.morphs(sample) \n",
        "  tokenized_sequences.append(tokenized_sample)\n",
        "\n",
        "  for word in tokenized_sample:\n",
        "    z = []\n",
        "    for i in markets:\n",
        "      if i in word:\n",
        "        z.append(i)\n",
        "\n",
        "    if word in remove_object_name_f_se1:\n",
        "      temp_sample.append('O')\n",
        "    else:\n",
        "      if 'B-STO' in temp_sample:\n",
        "        temp_sample.append('I-STO')\n",
        "      elif len(z) < 1:\n",
        "        temp_sample.append('B-STO')\n",
        "      else:\n",
        "        temp_sample.append('B-MAR')\n",
        "  label_sequences.append(temp_sample)        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KEOAvOKsmZf"
      },
      "source": [
        "q_df_invest_info_1 = pd.DataFrame()\n",
        "q_df_invest_info_1['qeustion'] = invest_info_1\n",
        "q_df_invest_info_1['results_tokenized'] = tokenized_sequences\n",
        "q_df_invest_info_1['results_named_entity_recognition'] = label_sequences"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "flO7oC70smeL",
        "outputId": "5bb9019f-6022-49da-fa18-ca51589aed1c"
      },
      "source": [
        "q_df_invest_info_1.iloc[np.r_[200:201, len(q_df_invest_info_1)-1:len(q_df_invest_info_1)],:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qeustion</th>\n",
              "      <th>results_tokenized</th>\n",
              "      <th>results_named_entity_recognition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>ARIRANG 200동일가중 트렌드 알려줘</td>\n",
              "      <td>[ARIRANG200, 동일, 가중, 트렌드, 알려줘]</td>\n",
              "      <td>[B-STO, I-STO, I-STO, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194885</th>\n",
              "      <td>코스닥주식 초보 기초정보</td>\n",
              "      <td>[코스닥, 주식, 초보, 기초, 정보]</td>\n",
              "      <td>[B-MAR, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       qeustion  ... results_named_entity_recognition\n",
              "200     ARIRANG 200동일가중 트렌드 알려줘  ...      [B-STO, I-STO, I-STO, O, O]\n",
              "194885            코스닥주식 초보 기초정보  ...              [B-MAR, O, O, O, O]\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC6nPTHPsmjz"
      },
      "source": [
        "    - 문장2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW1dJXIuX8JD",
        "outputId": "f49de3be-0c9e-41d1-b4e3-3fb2958bd926"
      },
      "source": [
        "q_invest_2_sample = question_invest_info_2(['코스피'], ['공매도'])\n",
        "\n",
        "samples_tokenized_invest_q2 = []\n",
        "for q in q_invest_2_sample:\n",
        "  samples_tokenized_invest_q2.append(mecab.morphs(q))\n",
        "\n",
        "remove_object_name_f_se2 = [X for sublist in samples_tokenized_invest_q2 for X in sublist if X != '코스피' and X != '공매도']\n",
        "remove_object_name_f_se2[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['에서', '현상', '이', '지속', '될', '만', '한', '금융상품', '뉴스', '를']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVpMNFM3TL3i"
      },
      "source": [
        "invest_info_2 = question_invest_info_2()\n",
        "\n",
        "tokenized_sequences = []\n",
        "label_sequences = []\n",
        "\n",
        "for sample in invest_info_2:\n",
        "  temp_sample = []\n",
        "  tokenized_sample = mecab.morphs(sample) \n",
        "  tokenized_sequences.append(tokenized_sample)\n",
        "\n",
        "  for word in tokenized_sample:\n",
        "    if word in remove_object_name_f_se2:\n",
        "      temp_sample.append('O')\n",
        "    else:\n",
        "      if 'B-MAR' in temp_sample:\n",
        "        temp_sample.append('B-VEL')\n",
        "      else:\n",
        "        temp_sample.append('B-MAR')\n",
        "  label_sequences.append(temp_sample)        "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88VOOPccV2m"
      },
      "source": [
        "q_df_invest_info_2 = pd.DataFrame()\n",
        "q_df_invest_info_2['qeustion'] = invest_info_2\n",
        "q_df_invest_info_2['results_tokenized'] = tokenized_sequences\n",
        "q_df_invest_info_2['results_named_entity_recognition'] = label_sequences"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "YFcyQo8ucV48",
        "outputId": "dfb5c146-b02b-47e7-9b1d-6b741ce9f26c"
      },
      "source": [
        "q_df_invest_info_2.iloc[np.r_[0:1, len(q_df_invest_info_2)-1:len(q_df_invest_info_2)],:]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qeustion</th>\n",
              "      <th>results_tokenized</th>\n",
              "      <th>results_named_entity_recognition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>비트코인에서 공매도현상이 지속될만한 금융상품 뉴스를 취합해줘</td>\n",
              "      <td>[비트코인, 에서, 공매도, 현상, 이, 지속, 될, 만, 한, 금융상품, 뉴스, ...</td>\n",
              "      <td>[B-MAR, O, B-VEL, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>소형주 배당금 상황이 어때?</td>\n",
              "      <td>[소형주, 배당금, 상황, 이, 어때, ?]</td>\n",
              "      <td>[B-MAR, B-VEL, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             qeustion  ...                   results_named_entity_recognition\n",
              "0   비트코인에서 공매도현상이 지속될만한 금융상품 뉴스를 취합해줘  ...  [B-MAR, O, B-VEL, O, O, O, O, O, O, O, O, O, O...\n",
              "69                    소형주 배당금 상황이 어때?  ...                         [B-MAR, B-VEL, O, O, O, O]\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbwv7O1lcV7c"
      },
      "source": [
        "    - 문장3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j60HHgsIcV9f",
        "outputId": "b0331eef-65dd-4ecf-d488-0d8c4fdefa28"
      },
      "source": [
        "q_invest_3_sample = ['11월 17일 3S 상승관련 이슈 취합해줘',\n",
        "                     '11월 17일 3S 상승관련 자료',\n",
        "                     '11월 첫째주 3S 상승']\n",
        "samples_tokenized_invest_q3 = []\n",
        "for q in q_invest_3_sample:\n",
        "  samples_tokenized_invest_q3.append(mecab.morphs(q))\n",
        "\n",
        "remove_object_name_f_se3 = [X for sublist in samples_tokenized_invest_q3 for X in sublist if X != '11월' and X != '17일' and X != '3S' and X != '상승' and X != '첫째주']\n",
        "remove_object_name_f_se3"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['관련', '이슈', '취합', '해', '줘', '관련', '자료']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsc_2EEooeTJ"
      },
      "source": [
        "invest_info_3 = question_invest_info_3()\n",
        "\n",
        "tokenized_sequences = []\n",
        "label_sequences = []\n",
        "\n",
        "for sample in invest_info_3:\n",
        "  temp_sample = []\n",
        "  tokenized_sample = mecab.morphs(sample) \n",
        "  tokenized_sequences.append(tokenized_sample)\n",
        "\n",
        "  for word in tokenized_sample:\n",
        "    z1 = []\n",
        "    for b in weeks:\n",
        "      if b in word:\n",
        "        z1.append(b)\n",
        "    z2 = []\n",
        "    if not '일' in word and not '월' in word and not '째주' in word: \n",
        "      if not word in markets:\n",
        "          z2.append(word)        \n",
        "\n",
        "    if word in remove_object_name_f_se3:\n",
        "      temp_sample.append('O')\n",
        "    else:\n",
        "      if word in volatility:\n",
        "        temp_sample.append('B-VEL')\n",
        "      else:\n",
        "        if word in markets:\n",
        "          temp_sample.append('B-MAR')\n",
        "        elif len(z1) < 1 and 'B-STO' in temp_sample:\n",
        "          temp_sample.append('I-STO')\n",
        "        elif len(z2) >= 1:\n",
        "          temp_sample.append('B-STO')\n",
        "        else:\n",
        "          if len(z1) >= 1:\n",
        "             temp_sample.append('B-WEK')\n",
        "          else:\n",
        "            if 'B-MON' in temp_sample:\n",
        "              temp_sample.append('B-DAY')\n",
        "            else:                           \n",
        "              temp_sample.append('B-MON')\n",
        "  label_sequences.append(temp_sample)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZRA09-XE3qO"
      },
      "source": [
        "q_df_invest_info_3 = pd.DataFrame()\n",
        "q_df_invest_info_3['qeustion'] = invest_info_3\n",
        "q_df_invest_info_3['results_tokenized'] = tokenized_sequences\n",
        "q_df_invest_info_3['results_named_entity_recognition'] = label_sequences"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "dyNLrxgnE3tC",
        "outputId": "2a15024a-15a8-4db3-d904-09f81ec80d4d"
      },
      "source": [
        "q_df_invest_info_3.iloc[np.r_[298:299, len(q_df_invest_info_3)-1:len(q_df_invest_info_3)],:]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qeustion</th>\n",
              "      <th>results_tokenized</th>\n",
              "      <th>results_named_entity_recognition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>7월 5일 ARIRANG 국채선물3년 급등관련 자료</td>\n",
              "      <td>[7월, 5일, ARIRANG, 국채선물, 3년, 급등, 관련, 자료]</td>\n",
              "      <td>[B-MON, B-DAY, B-STO, I-STO, I-STO, B-VEL, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86615</th>\n",
              "      <td>8월 첫째주 코스닥 급등</td>\n",
              "      <td>[8월, 첫째주, 코스닥, 급등]</td>\n",
              "      <td>[B-MON, B-WEK, B-MAR, B-VEL]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           qeustion  ...                  results_named_entity_recognition\n",
              "298    7월 5일 ARIRANG 국채선물3년 급등관련 자료  ...  [B-MON, B-DAY, B-STO, I-STO, I-STO, B-VEL, O, O]\n",
              "86615                 8월 첫째주 코스닥 급등  ...                      [B-MON, B-WEK, B-MAR, B-VEL]\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mczVBhIDXWa"
      },
      "source": [
        "###### 의도 투자정보에 대한 데이터프레임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pmHyl-n84k5A",
        "outputId": "069042b8-c332-41cb-c1f0-a52f110cbd7c"
      },
      "source": [
        "df_invest_info_final = pd.concat([q_df_invest_info_1, q_df_invest_info_2, q_df_invest_info_3])\n",
        "df_invest_info_final['intent'] = '투자정보'"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qeustion</th>\n",
              "      <th>results_tokenized</th>\n",
              "      <th>results_named_entity_recognition</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3S 투자관련 지식정보</td>\n",
              "      <td>[3S, 투자, 관련, 지식, 정보]</td>\n",
              "      <td>[B-STO, O, O, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3S 최근 이슈</td>\n",
              "      <td>[3S, 최근, 이슈]</td>\n",
              "      <td>[B-STO, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3S 필수정보</td>\n",
              "      <td>[3S, 필수, 정보]</td>\n",
              "      <td>[B-STO, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3S 트렌트 탐색</td>\n",
              "      <td>[3S, 트렌트, 탐색]</td>\n",
              "      <td>[B-STO, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3S 주식투자에 필요한 기사 알려줘</td>\n",
              "      <td>[3S, 주식, 투자, 에, 필요, 한, 기사, 알려줘]</td>\n",
              "      <td>[B-STO, O, O, O, O, O, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86611</th>\n",
              "      <td>1월 11일 코스닥 정체관련 자료</td>\n",
              "      <td>[1월, 11일, 코스닥, 정체, 관련, 자료]</td>\n",
              "      <td>[B-MON, B-DAY, B-MAR, B-VEL, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86612</th>\n",
              "      <td>11월 넷째주 코스닥 정체</td>\n",
              "      <td>[11월, 넷째주, 코스닥, 정체]</td>\n",
              "      <td>[B-MON, B-WEK, B-MAR, B-VEL]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86613</th>\n",
              "      <td>5월 19일 코스닥 급등관련 이슈 취합해줘</td>\n",
              "      <td>[5월, 19일, 코스닥, 급등, 관련, 이슈, 취합, 해, 줘]</td>\n",
              "      <td>[B-MON, B-DAY, B-MAR, B-VEL, O, O, O, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86614</th>\n",
              "      <td>1월 17일 코스닥 급등관련 자료</td>\n",
              "      <td>[1월, 17일, 코스닥, 급등, 관련, 자료]</td>\n",
              "      <td>[B-MON, B-DAY, B-MAR, B-VEL, O, O]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86615</th>\n",
              "      <td>8월 첫째주 코스닥 급등</td>\n",
              "      <td>[8월, 첫째주, 코스닥, 급등]</td>\n",
              "      <td>[B-MON, B-WEK, B-MAR, B-VEL]</td>\n",
              "      <td>투자정보</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>281572 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      qeustion  ... intent\n",
              "0                 3S 투자관련 지식정보  ...   투자정보\n",
              "1                     3S 최근 이슈  ...   투자정보\n",
              "2                      3S 필수정보  ...   투자정보\n",
              "3                    3S 트렌트 탐색  ...   투자정보\n",
              "4          3S 주식투자에 필요한 기사 알려줘  ...   투자정보\n",
              "...                        ...  ...    ...\n",
              "86611       1월 11일 코스닥 정체관련 자료  ...   투자정보\n",
              "86612           11월 넷째주 코스닥 정체  ...   투자정보\n",
              "86613  5월 19일 코스닥 급등관련 이슈 취합해줘  ...   투자정보\n",
              "86614       1월 17일 코스닥 급등관련 자료  ...   투자정보\n",
              "86615            8월 첫째주 코스닥 급등  ...   투자정보\n",
              "\n",
              "[281572 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4WzTpReDn_n"
      },
      "source": [
        "df_invest_info_final.to_csv('df_invest_info_final.csv', index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7m1_7Qb4l35"
      },
      "source": [
        "### ***의도2 : 가격***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u-Cxv1B4l6w"
      },
      "source": [
        "###### ***질물생성_1 (의도 :  가격정보)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQr_cvx14l_J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URnjjbyk4mCx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1NVzypG4mFG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJLx2CaA4mNO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apnBBwH4mPf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjBCLQsp4mUi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNE7GbUi4mXh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJGeLKS4mZs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXKMJnJ4mci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izp14qDO4mfC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOpEU0RH4mhs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aElgcK64mkq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h1HEZHe4mnY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wzq-a9w4mqB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjTcXFG14mtL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeMhw77v4mvX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymmv9yOj4mxx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSU70wJRQ-hb"
      },
      "source": [
        "###### 보류문장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odqBdLWwQ-jQ"
      },
      "source": [
        "# 개체명 구성 : STO, IND\n",
        "Sector = df_krx.dropna(axis=0)['Sector'].dropna().tolist()\n",
        "stock_name = df_krx.Name.tolist()\n",
        "\n",
        "def question_invest_info_4(list_1 = Sector, list_2 = stock_name):\n",
        "  se_4 = []\n",
        "  for i in range(len(list_1)):\n",
        "    n_sector = list_1[i].replace(\" \",\"\")\n",
        "    n_sector = re.sub(r'[.,!<>/=?\"\\':;~()]', '', n_sector)\n",
        "    s1 = f'{list_2[i]} {n_sector}의 미래 가치는?'\n",
        "    s2 = f'{list_2[i]} {n_sector} 향후 전망'\n",
        "    s3 = f'{list_2[i]} {n_sector} 발전 가능성'\n",
        "    se_4 = se_4+[s1, s2, s3]\n",
        "  return se_4    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DevcGEoJQ-lP"
      },
      "source": [
        "q_invest_4_sample = ['APS홀딩스 금융업의 미래 가치는?',\n",
        "                     'APS홀딩스 금융업 향후 전망',\n",
        "                     'APS홀딩스 금융업 발전 가능성']\n",
        "\n",
        "samples_tokenized_invest_q4 = []\n",
        "for q in q_invest_4_sample:\n",
        "  samples_tokenized_invest_q4.append(mecab.morphs(q))\n",
        "\n",
        "remove_object_name_f_se4 = [X for sublist in samples_tokenized_invest_q4 for X in sublist if X != 'APS홀딩스' and X != '금융업']\n",
        "remove_object_name_f_se4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg2kfy_h3-mG"
      },
      "source": [
        "invest_info_4 = question_invest_info_4()\n",
        "\n",
        "invest_info_4_sentences_stock = []\n",
        "invest_info_4_sentences_sector = []\n",
        "for sentence in invest_info_4:\n",
        "  # invest_info_4_sentences_stock.append(sentence.split(\" \", 1)[0])\n",
        "  invest_info_4_sentences_sector.append(sentence.split(\" \", 1)[1])\n",
        "\n",
        "tokenized_sequences_0 = []\n",
        "label_sequences_0 = []\n",
        "for sample in invest_info_4_sentences_sector:\n",
        "  temp_sample = []\n",
        "  tokenized_sample = mecab.morphs(sample) \n",
        "  tokenized_sequences_0.append(tokenized_sample)\n",
        "  for word in tokenized_sample:\n",
        "    if word in remove_object_name_f_se4:\n",
        "      temp_sample.append('O')\n",
        "    else:\n",
        "      if 'B-IND' in temp_sample:\n",
        "        temp_sample.append('I-IND')\n",
        "      else:\n",
        "        temp_sample.append('B-IND')\n",
        "  label_sequences_1.append(temp_sample)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "tokenized_sequences = []\n",
        "label_sequences = []\n",
        "for sample in invest_info_4:\n",
        "  temp_sample = []\n",
        "  tokenized_sample = mecab.morphs(sample) \n",
        "  tokenized_sequences.append(tokenized_sample)\n",
        "\n",
        "  space_to_allocate_stock = len(tokenized_sample) - len(label_sequences_1)\n",
        "  temp_sample = [['B-STO'], list(itertools.repeat('I-STO', space_to_allocate_stock -1))]\n",
        "  temp_sample = sum(temp_sample,[])\n",
        "  t = [temp_sample, label_sequences_1[idx]]\n",
        "  temp_sample_new = sum(t, [])\n",
        "  idx += 1\n",
        "  label_sequences.append(temp_sample_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEiKq2Fy4A-h"
      },
      "source": [
        "q_df_invest_info_4 = pd.DataFrame()\n",
        "q_df_invest_info_4['qeustion'] = invest_info_4\n",
        "q_df_invest_info_4['results_tokenized'] = tokenized_sequences\n",
        "q_df_invest_info_4['results_named_entity_recognition'] = label_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpVL7f1U1rJj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPJKDC74saWq"
      },
      "source": [
        "###### passing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H1N3ZO8i8p3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VvNpk0-T8ed"
      },
      "source": [
        "names = stock_list\n",
        "\n",
        "def question_generator(names):\n",
        "    question = []\n",
        "    for name in names:\n",
        "        s1 = name+' 알려줘'\n",
        "        s2 = name+'에 대해 알려줘'\n",
        "        s3 = name+' 관련 뉴스 보여줘'\n",
        "        s4 = name+' 기사 보여줘'\n",
        "        s5 = name+' 주식투자에 필요한 기사 알려줘'\n",
        "        s6 = name+' 주식에 필요한 내용 알려줘'\n",
        "        s7 = name+' 주식 관련 추천기사 알려줘'\n",
        "        s8 = name+' 추천기사'\n",
        "        s9 = name+' 추천뉴스'\n",
        "        s10 = name+' 트렌드'\n",
        "        s11 = name+' 트렌드 알려줘'\n",
        "        s12 = name+'를 분석해주세요'\n",
        "        s13 = name+' 분석해봐'\n",
        "        s14 = name+' 인기있는 기사'\n",
        "        s15 = name+'의 가장 핫한 이슈가 뭐야'\n",
        "        s16 = name+'의 반드시 알아야 할 내용'\n",
        "        s17 = name+' 트렌드 알려줘'\n",
        "        s18 = name+' 분석해봐'\n",
        "        s19 = name+' 인기있는 기사'\n",
        "        s20 = name+'의 가장 핫한 이슈가 뭐야'\n",
        "        s21 = name+'의 반드시 알아야 할 내용'\n",
        "        s22 = name+' 소식'\n",
        "        s23 = name+' 소식 요약해줘'\n",
        "        s24 = name+' 요약해줘'\n",
        "        s25 = name+' 투자에 필요한 기사'\n",
        "        s26 = name+' 투자에 알아야 할 기사'\n",
        "        s27 = name+' 투자에 알아야 할 뉴스'\n",
        "        s28 = name+' 필수내용'\n",
        "        s29 = name+' 주요기사'\n",
        "        s30 = name+' 주요뉴스'\n",
        "        s31 = name+' 사업개요 알려줘'\n",
        "        s32 = name+' 사업 개요가 궁금해'\n",
        "        s33 = name+'를 분석해줘'\n",
        "        s34 = name+' 분석'\n",
        "        s35 = name+' 요약해줘'\n",
        "        s36 = name+' 요약해주세요'\n",
        "        s37 = name+' 요약해봐'\n",
        "        s38 = name+'를 분석해주세요'\n",
        "        s39 = name+' 분석해봐'\n",
        "        s40 = name+' 요약'\n",
        "        s41 = name+' 개요'\n",
        "        s42 = name+'에 대해 개요를 알려줘봐'\n",
        "        s43 = name+'의 사업 개요는 뭐야'\n",
        "        s44 = name+'에 대해서 요약해줘'\n",
        "        s45 = name+' 기업 개요를 알려줘'\n",
        "        s46 = name+' 기업 개요를 말해봐'\n",
        "        s47 = name+'의 개요는 뭘까'\n",
        "        s48 = name+'의 개요가 뭐야?'\n",
        "        s49 = name+'사업 개요를 요약해줘'\n",
        "        s50 = name+'에 대해서 요약해줘'\n",
        "        s51 = name+'를 요약 해줘'\n",
        "        s52 = name+'를 요약 분석한다면?'\n",
        "\n",
        "        question = question+[s1, s2, s3, s4, s5, s6, s6, s7, s8, s9, s10, s11, s12, s13, s15, s16, s17, s18, s19, s20, s21, s22, s23, s24, s25, s26, s27, s28, s29, s30,\n",
        "                             s31, s32, s33, s34, s35, s36, s37, s38, s39, s40, s41, s42, s43, s44, s45, s46, s47, s48, s49, s50, s51, s52]\n",
        "    return question\n",
        "\n",
        "analysis = question_generator(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q75pPMmzcptw",
        "outputId": "4d020a34-02d4-4c80-cb5c-d643b76cd152"
      },
      "source": [
        "analysis[len(analysis) - 5:len(analysis)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['힘스 투자에 알아야 할 기사', '힘스 투자에 알아야 할 뉴스', '힘스 필수내용', '힘스 주요기사', '힘스 주요뉴스']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17oS2Nsm73K"
      },
      "source": [
        "from ekonlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFVXoD2Cg1s4"
      },
      "source": [
        "# tokenized_test_result = []\n",
        "# for sample_keyword_question in analysis:\n",
        "#   tokenized_test_result.append(mecab.morphs(sample_keyword_question))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjcuHri4pg1h"
      },
      "source": [
        "analysis_data = {'question' : analysis, 'intent' : ['투자정보']*len(analysis)}\n",
        "analysis_df = pd.DataFrame(similarity_data, columns=('question', 'intent'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywtShX8_2ffk"
      },
      "source": [
        "중략\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joSnsO0iqNwx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR3VKSFyi-Tc"
      },
      "source": [
        "# 크로링 및 모델학습 구간"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrL_LIsE9ZiG"
      },
      "source": [
        "***네이버 기사 및 링크 크롤링 테스트***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vahk24RoO9J7"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "import FinanceDataReader as fdr\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import quote\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def get_news(stock_name, pages):\n",
        "\n",
        "  stock_ns_df = pd.DataFrame(columns = ('Title', 'Adress'))\n",
        "  idx = 0\n",
        "\n",
        "  url_query = quote(stock_name)\n",
        "\n",
        "  for pg_rng in range(pages):\n",
        "    url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query=' + url_query + str('&start=' + str(pg_rng * 10 + 1))\n",
        "\n",
        "    surf_url = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(surf_url, 'html.parser')\n",
        "    links = soup.find_all('div', {'class':'news_wrap api_ani_send'})\n",
        "    titls = soup.find_all('a', {'class':'news_tit'})\n",
        "    dates = soup.find_all('span', {'class':'info'})\n",
        "\n",
        "    for i in range(len(links)):\n",
        "      news_url = links[i].find('a').get('href')\n",
        "      news_titl = titls[i].get('title')\n",
        "\n",
        "      stock_ns_df.loc[idx] = [news_titl, news_url]\n",
        "      idx += 1\n",
        "\n",
        "  return stock_ns_df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iBxWc1KKNG7"
      },
      "source": [
        "comp_list_1 = ['코콤',\n",
        "             '에스넷',\n",
        "             '상지카일홈',\n",
        "             '현대통신',\n",
        "             '코맥스',\n",
        "             '에스원',\n",
        "             'HDC아이콘트롤스',\n",
        "             '유양디앤유',\n",
        "             '경동나비엔',\n",
        "             '피에스텍',\n",
        "             '포스코ICT',\n",
        "             '누리텔레콤',\n",
        "             '옴니시스템',\n",
        "             '현대리바트',\n",
        "             '위닉스',\n",
        "             '엠젠플러스',\n",
        "             'GS건설',\n",
        "             'LG전자',\n",
        "             '삼성전자',\n",
        "             'Sk텔레콤',\n",
        "             'KT',\n",
        "             'LG유플러스']\n",
        "\n",
        "df_list = []\n",
        "for crawling_by_cny in range(len(comp_list_1)):\n",
        "  sub_df = get_news(comp_list[crawling_by_cny], 10)\n",
        "  df_list.append(sub_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-irYy5aBLaZ"
      },
      "source": [
        "df_result = pd.concat(df_list, axis=0)\n",
        "df_result.to_excel('labeling_test.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BMvQ8kK7bSO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2OSeu_H9T6p"
      },
      "source": [
        "***재무재표 크롤링 Test***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8GFooHi5-Bs8",
        "outputId": "5be4b326-a2e6-4ef6-a6ef-7fe6c6b55e5d"
      },
      "source": [
        "# symbol crawling\n",
        "df_krx = fdr.StockListing('KRX')\n",
        "df_symbol = df_krx[['Symbol', 'Name']]\n",
        "df_symbol.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7010</th>\n",
              "      <td>000547</td>\n",
              "      <td>흥국화재2우B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7011</th>\n",
              "      <td>000545</td>\n",
              "      <td>흥국화재우</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7012</th>\n",
              "      <td>003280</td>\n",
              "      <td>흥아해운</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7013</th>\n",
              "      <td>037440</td>\n",
              "      <td>희림</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7014</th>\n",
              "      <td>238490</td>\n",
              "      <td>힘스</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Symbol     Name\n",
              "7010  000547  흥국화재2우B\n",
              "7011  000545    흥국화재우\n",
              "7012  003280     흥아해운\n",
              "7013  037440       희림\n",
              "7014  238490       힘스"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUVP3yiV7aZC"
      },
      "source": [
        "def crawling_financial_statement(company_name):\n",
        "  symbol_idx = np.where(df_symbol.Name == company_name)[0][0]\n",
        "  symbol = df_symbol.Symbol[symbol_idx]\n",
        "\n",
        "  URL = f\"https://finance.naver.com/item/main.nhn?code={symbol}\"\n",
        "\n",
        "  statement_info = requests.get(URL)\n",
        "  html = statement_info.text\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  finance_html = soup.select('div.section.cop_analysis div.sub_section')[0]\n",
        "\n",
        "  th_data = [item.get_text().strip() for item in finance_html.select('thead th')]\n",
        "  annual_date = th_data[3:7]\n",
        "  quarter_date = th_data[7:13]\n",
        "  finance_index = [item.get_text().strip() for item in finance_html.select('th.h_th2')][3:]\n",
        "  finance_data = [item.get_text().strip() for item in finance_html.select('td')]\n",
        "  finance_data = np.array(finance_data)\n",
        "  finance_data.resize(len(finance_index), 10)\n",
        "  finance_date = annual_date + quarter_date\n",
        "\n",
        "  finance = pd.DataFrame(data=finance_data[0:,0:], index=finance_index, columns=finance_date)\n",
        "  return finance.iloc[:, :4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "eSYcmyhp8TnU",
        "outputId": "433d5998-9b10-45ff-9592-96a7c238f9d3"
      },
      "source": [
        "crawling_financial_statement('현대통신')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2018.12</th>\n",
              "      <th>2019.12</th>\n",
              "      <th>2020.12</th>\n",
              "      <th>2021.12(E)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>매출액</th>\n",
              "      <td>1,273</td>\n",
              "      <td>1,046</td>\n",
              "      <td>1,037</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>영업이익</th>\n",
              "      <td>201</td>\n",
              "      <td>105</td>\n",
              "      <td>86</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>당기순이익</th>\n",
              "      <td>170</td>\n",
              "      <td>107</td>\n",
              "      <td>91</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>영업이익률</th>\n",
              "      <td>15.78</td>\n",
              "      <td>10.04</td>\n",
              "      <td>8.32</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>순이익률</th>\n",
              "      <td>13.39</td>\n",
              "      <td>10.20</td>\n",
              "      <td>8.81</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROE(지배주주)</th>\n",
              "      <td>25.22</td>\n",
              "      <td>13.60</td>\n",
              "      <td>10.89</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>부채비율</th>\n",
              "      <td>47.86</td>\n",
              "      <td>33.92</td>\n",
              "      <td>25.62</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>당좌비율</th>\n",
              "      <td>146.69</td>\n",
              "      <td>178.32</td>\n",
              "      <td>171.73</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>유보율</th>\n",
              "      <td>1,672.26</td>\n",
              "      <td>1,852.01</td>\n",
              "      <td>2,014.14</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EPS(원)</th>\n",
              "      <td>1,977</td>\n",
              "      <td>1,236</td>\n",
              "      <td>1,059</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER(배)</th>\n",
              "      <td>5.46</td>\n",
              "      <td>6.49</td>\n",
              "      <td>7.67</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BPS(원)</th>\n",
              "      <td>8,719</td>\n",
              "      <td>9,685</td>\n",
              "      <td>10,736</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PBR(배)</th>\n",
              "      <td>1.24</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.76</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>주당배당금(원)</th>\n",
              "      <td>300</td>\n",
              "      <td>300</td>\n",
              "      <td>350</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>시가배당률(%)</th>\n",
              "      <td>2.78</td>\n",
              "      <td>3.74</td>\n",
              "      <td>4.31</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>배당성향(%)</th>\n",
              "      <td>15.18</td>\n",
              "      <td>23.70</td>\n",
              "      <td>30.76</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            2018.12   2019.12   2020.12 2021.12(E)\n",
              "매출액           1,273     1,046     1,037           \n",
              "영업이익            201       105        86           \n",
              "당기순이익           170       107        91           \n",
              "영업이익률         15.78     10.04      8.32           \n",
              "순이익률          13.39     10.20      8.81           \n",
              "ROE(지배주주)     25.22     13.60     10.89           \n",
              "부채비율          47.86     33.92     25.62           \n",
              "당좌비율         146.69    178.32    171.73           \n",
              "유보율        1,672.26  1,852.01  2,014.14           \n",
              "EPS(원)        1,977     1,236     1,059           \n",
              "PER(배)         5.46      6.49      7.67           \n",
              "BPS(원)        8,719     9,685    10,736           \n",
              "PBR(배)         1.24      0.83      0.76           \n",
              "주당배당금(원)        300       300       350           \n",
              "시가배당률(%)       2.78      3.74      4.31           \n",
              "배당성향(%)       15.18     23.70     30.76           "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRJuZ9XX0VI3"
      },
      "source": [
        ".\n",
        "\n",
        ".\n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "0W1lV62wBLfS",
        "outputId": "033f6e84-3de9-46d1-af92-f76ed764c103"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b610c075-3f8e-4e35-8682-4b1a948b79d9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b610c075-3f8e-4e35-8682-4b1a948b79d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Intent_jh.xlsx to Intent_jh.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ4H4eMgBLhZ"
      },
      "source": [
        "import io\n",
        "df_intent = pd.read_excel(io.BytesIO(uploaded['Intent_jh.xlsx']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7FY_-FlA1mrm",
        "outputId": "32c1c162-5e52-47f0-9f36-64449a745c35"
      },
      "source": [
        "df_intent = df_intent[['Title', 'Adress']]\n",
        "df_intent.columns = ['article', 'intent']\n",
        "df_intent.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2194</th>\n",
              "      <td>LGU+ 온라인몰 '유샵', 국내 최초 자급제폰 개통 원스톱 서비스</td>\n",
              "      <td>전략</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2195</th>\n",
              "      <td>SK텔레콤·LG유플러스, 상승에 급등으로 훨훨…SK텔레콤 6% 급등 이어 LG유플러...</td>\n",
              "      <td>주가전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2196</th>\n",
              "      <td>디즈니+, KT·LG U+와 3분기 상륙.. 미디어 업계 분주</td>\n",
              "      <td>시장전망</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2197</th>\n",
              "      <td>LG유플러스, ESG 경영 강화 위해 모니터링 시스템 구축</td>\n",
              "      <td>사업확장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>LGU+ 황현식, 100개 국사에 에너지 모니터링 시스템 구축</td>\n",
              "      <td>사업확장</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                article intent\n",
              "2194              LGU+ 온라인몰 '유샵', 국내 최초 자급제폰 개통 원스톱 서비스     전략\n",
              "2195  SK텔레콤·LG유플러스, 상승에 급등으로 훨훨…SK텔레콤 6% 급등 이어 LG유플러...   주가전망\n",
              "2196                 디즈니+, KT·LG U+와 3분기 상륙.. 미디어 업계 분주   시장전망\n",
              "2197                   LG유플러스, ESG 경영 강화 위해 모니터링 시스템 구축   사업확장\n",
              "2198                 LGU+ 황현식, 100개 국사에 에너지 모니터링 시스템 구축   사업확장"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_IU79_o2mj5",
        "outputId": "13e47ae5-22ea-4033-f64c-1a8749eaf6d8"
      },
      "source": [
        "df_intent = df_intent.dropna(how='any', axis=0)\n",
        "df_intent.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9YFOaoX3CEY"
      },
      "source": [
        "# df_intent.intent.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMoe1Hz53aoM"
      },
      "source": [
        "error = ['주가전망', '전력', '주가정망']\n",
        "for i in range(3):\n",
        "  df_intent = df_intent[df_intent.intent != error[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMYN4Q9_4aFI",
        "outputId": "a9e881b0-d03d-4ae5-e4b2-f3cd7b330b7e"
      },
      "source": [
        "df_intent.intent.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "주식전망    123\n",
              "전략      100\n",
              "홍보       97\n",
              "사업확장     83\n",
              "시장전망     37\n",
              "기타       32\n",
              "매출       21\n",
              "Name: intent, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb72U4NTLtHW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMcSMVTTQC3B",
        "outputId": "fa525851-300c-4194-a440-0bf2f80792f7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "!apt -qq -y install fonts-nanum\n",
        "\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following packages were automatically installed and are no longer required:\n",
            "  r-cran-covr r-cran-crosstalk r-cran-dt r-cran-htmlwidgets r-cran-later\n",
            "  r-cran-lazyeval r-cran-promises r-cran-rex\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 161272 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXfGJyVHLvNp",
        "outputId": "418c6614-82f9-4266-ea1b-8c7b023e5520"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFd_aQ604cWw"
      },
      "source": [
        "okt = Okt()\n",
        "\n",
        "X_train = []\n",
        "for sentence in df_intent.article:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence)\n",
        "    X_train.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwfQL_D5O4Pk",
        "outputId": "83474cf7-4062-4474-e248-02c1cae0db2e"
      },
      "source": [
        "X_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['주', '총', '통해', '살펴본', '조명', '상', '장사', ',', '위기', '탈출', '전략', '은'],\n",
              " ['김기훈', '코콤', '포터', '노벨', '리', '대표', ',', '한국', 'PR', '기업', '협회장', '선출'],\n",
              " ['코콤', ',', '비행기', '지', '통합', '관제', '체계', '구축', '사업', '수주']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8cOGN4RPb5_"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqVYMSwrPcY7"
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XaB0PLBPfcz",
        "outputId": "263c6567-60ed-4e4e-fa57-0e09f5bfbcfa"
      },
      "source": [
        "X_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[103, 319, 320, 594, 595, 596, 597, 1, 408, 176, 598, 150],\n",
              " [599, 177, 600, 601, 409, 410, 1, 116, 602, 64, 603, 604],\n",
              " [177, 1, 605, 117, 321, 411, 606, 65, 15, 253]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaVVoGNfPin-",
        "outputId": "9ce17271-616b-4e32-8205-adc31a444ade"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{',': 1, \"'\": 2, '통신': 3, 'kt': 4, '현대': 5, '카일': 6, '룸': 7, '상지': 8, '에스': 9, '넷': 10, 'lg': 11, '유플러스': 12, '\"': 13, '…': 14, '사업': 15, '-': 16, '서비스': 17, '시스템': 18, '·': 19, '디지털': 20, '[': 21, '+': 22, 'b': 23, ']': 24, '한': 25, '현재': 26, '주가': 27, '헬': 28, '스케': 29, '어': 30, '확대': 31, '교육': 32, 'vi': 33, '발동': 34, '바이오': 35, '에': 36, '로': 37, '협력': 38, '‘': 39, '주식': 40, '와': 41, '테라': 42, '젠': 43, 'lgu': 44, '개통': 45, '과': 46, '빅데이터': 47, '’': 48, '2': 49, '발굴': 50, '돌봄': 51, '+,': 52, '맞': 53, '손': 54, '상승': 55, '용산구': 56, '그룹': 57, '아이': 58, '오피스텔': 59, '시작': 60, '제': 61, 'm': 62, '온라인': 63, '기업': 64, '구축': 65, '정보': 66, '출시': 67, '위': 68, '대': 69, '헬스': 70, '패스': 71, '원스톱': 72, '자급': 73, '폰': 74, '성장': 75, '학원': 76, '협회': 77, '들': 78, '솔루션': 79, '규모': 80, '과징금': 81, 'sk': 82, 'kmac': 83, '6월': 84, '시장': 85, '매출': 86, '관리': 87, '코로나': 88, '원': 89, '개발': 90, '분양': 91, '유': 92, '4월': 93, '스마트': 94, '기반': 95, '“': 96, '도입': 97, '도': 98, '증권': 99, \"',\": 100, '형': 101, '전일': 102, '주': 103, '체결': 104, '”': 105, '병원': 106, '경영': 107, '텔레콤': 108, '투자': 109, '맞춤': 110, '...': 111, '지연': 112, '요': 113, '사회': 114, '샵': 115, '한국': 116, '지': 117, '증가': 118, '인수': 119, '전환': 120, '플랫폼': 121, 'it': 122, '전': 123, '제공': 124, '기': 125, '대상': 126, '20': 127, '종목': 128, '폭': 129, '대비': 130, '중소': 131, '랜선': 132, '에듀': 133, '공헌': 134, '홀맨': 135, '위해': 136, '업무': 137, '분': 138, '취득': 139, '(': 140, '분석': 141, '영업': 142, '노트': 143, '피크닉': 144, '컨설팅': 145, '출입': 146, '대사': 147, '취약': 148, '계층': 149, '은': 150, 'mou': 151, '클라우드': 152, '인프라': 153, '직원': 154, '오늘': 155, '↑': 156, '첫': 157, '자회사': 158, '부과': 159, '∙': 160, '이익': 161, '이': 162, '본격': 163, '추진': 164, '에이스': 165, '배당': 166, '약': 167, 'esg': 168, '방통위': 169, '세트': 170, '양병': 171, '능률': 172, '오픈': 173, '홍보': 174, '위촉': 175, '탈출': 176, '코콤': 177, '한다': 178, '금융': 179, '공급': 180, '인사': 181, '등': 182, '..': 183, '으로': 184, '미래': 185, ')': 186, '에도': 187, '매수': 188, '부동산': 189, '아파트': 190, '규제': 191, '진출': 192, '바이': 193, '오메': 194, '드': 195, '특별': 196, '7월': 197, '그래프': 198, '공모전': 199, '박경수': 200, '만루': 201, '제로': 202, '웨': 203, '이스트': 204, '몰': 205, \"'…\": 206, '29일': 207, '면': 208, '인성': 209, '공장': 210, 'ai': 211, '장': 212, '지원': 213, '데이터': 214, '의': 215, '강화': 216, '더벨': 217, '기술': 218, '4': 219, '서': 220, '19': 221, '계약': 222, '개최': 223, '방역': 224, '전망': 225, '역량': 226, '실시간': 227, '?': 228, '겨냥': 229, '강남': 230, '주거': 231, '종': 232, '속사': 233, '키트': 234, '마스크': 235, '관계자': 236, '변동': 237, '사': 238, '10350원': 239, '0.00%': 240, '9일': 241, '시세': 242, '10250원': 243, '용': 244, '보급': 245, 'digico': 246, '벤': 247, '처': 248, '안전한': 249, '아동': 250, '건강': 251, '에너지': 252, '수주': 253, '콜센터': 254, '재택근무': 255, '협약': 256, '비대': 257, '달성': 258, '공동': 259, '속': 260, '화': 261, '결정': 262, '나': 263, '진행': 264, '지난해': 265, '가': 266, '서울시': 267, '공공': 268, '와이파이': 269, '가속': 270, '티': 271, '살균': 272, '서울': 273, '훼': 274, '밀리': 275, '키퍼': 276, '는': 277, '세': 278, '에이치': 279, '5': 280, 'g': 281, '고': 282, '돕는다': 283, 's': 284, '외국인': 285, '달': 286, '럭셔리': 287, '주목': 288, '주택': 289, '고급': 290, '10%': 291, '이상': 292, '순': 293, '…\"': 294, '현': 295, '공식': 296, '하락': 297, '자': 298, '10050원': 299, '5월': 300, '24일': 301, '22일': 302, '현황': 303, '25일': 304, '한국판': 305, '실리콘밸리': 306, '이끌': 307, '갤': 308, '갤럭시': 309, '1억': 310, '스타': 311, '승': 312, '미디어': 313, '연패': 314, '탈모': 315, '유전체': 316, 'u': 317, '최초': 318, '총': 319, '통해': 320, '통합': 321, 'skt': 322, '판매': 323, '공략': 324, '개시': 325, '임': 326, '근': 327, '스톡옵션': 328, '부여': 329, '전환사채': 330, '발행': 331, '3년': 332, '내': 333, '를': 334, '위원회': 335, 'iot': 336, '도약': 337, '시스코': 338, '감염': 339, '확산': 340, '한화': 341, \"]'\": 342, '배': 343, '년': 344, '比': 345, '눈길': 346, '플': 347, '보안': 348, '격': 349, '공정위': 350, '바이러스': 351, '2분': 352, '실적': 353, '새': 354, '수': 355, '관련': 356, '현장': 357, '하나': 358, '2년': 359, '째': 360, '기관': 361, '강남구': 362, '적자': 363, '중': 364, '3': 365, '2030': 366, '세대': 367, '`': 368, '논현동': 369, '다음': 370, '청약': 371, '건설': 372, '진단': 373, '수출': 374, '적용': 375, '반사': 376, '재': 377, '변경': 378, '모비스': 379, '사주': 380, '!': 381, '양자암호': 382, '17일': 383, '8일': 384, '10300원': 385, '3월': 386, '10450원': 387, '증시': 388, '3일': 389, '1일': 390, '5%': 391, '10600원': 392, '단신': 393, '나선다': 394, '고의': 395, '양': 396, '홈런': 397, '\"…': 398, '관악': 399, '밸리': 400, '돕는': 401, '일환': 402, '고영표': 403, '포': 404, '두산': 405, '비만': 406, '국내': 407, '위기': 408, '리': 409, '대표': 410, '관제': 411, '스마트홈': 412, '알서포트': 413, 'sro': 414, '권': 415, '\\xa0': 416, '유지': 417, '200억원': 418, ';': 419, 'bnk': 420, '존': 421, '성': 422, '된': 423, '나서': 424, '도전': 425, '고도화': 426, '웨비': 427, '호조': 428, '부산시': 429, '저작권': 430, '아모': 431, '년비': 432, '목표': 433, '證': 434, 'cb': 435, '무료': 436, '프로젝트': 437, '작년': 438, '까지': 439, '협업': 440, '시': 441, '큐': 442, '운영': 443, '디': 444, '네이버': 445, '터널': 446, '과기부': 447, '공사': 448, 'swan': 449, 'ict': 450, '올해': 451, '소독제': 452, '1조원': 453, '두': 454, '활용': 455, '회장': 456, '신': 457, '지속': 458, '하반기': 459, '발표': 460, '케이': 461, '2020': 462, '종합': 463, '3분': 464, '038680': 465, '알파': 466, '/': 467, '수급': 468, '추가': 469, '확률': 470, '선': 471, '법인': 472, '명의': 473, '홀로': 474, '족': 475, '스몰': 476, '구': 477, '수요': 478, '뚜렷': 479, '예정': 480, '강남구청역': 481, '기대': 482, '퀀투퀄': 483, '트렌드': 484, '상품': 485, '각광': 486, '만': 487, '어디': 488, '’…': 489, '업종': 490, '상승세': 491, '8%': 492, '발전': 493, '시설': 494, '손실': 495, '허가': 496, '승인': 497, 'k': 498, '청구': 499, '소송': 500, '신속': 501, '시대': 502, '대량': 503, \"'-\": 504, '거래': 505, '량': 506, '0.94%': 507, '株': 508, '3억': 509, '용산': 510, '가액': 511, '조정': 512, '신탁': 513, '제휴': 514, '사용': 515, '20억': 516, '매각': 517, '사명': 518, '뉴스': 519, '주당': 520, '시가': 521, '이동통신': 522, '체크': 523, '현금': 524, '마감': 525, '입찰': 526, '담합': 527, '칼슨': 528, '은광': 529, '제재': 530, 'fnrassi': 531, '대학생': 532, '통신원': 533, '하세요': 534, '26일': 535, '100': 536, '성공': 537, '12일': 538, '10500원': 539, '28일': 540, '0.10%': 541, '4일': 542, '9850원': 543, '18일': 544, '검색': 545, '9160원': 546, '10일': 547, '27일': 548, '10150원': 549, '금일': 550, '9840원': 551, '8월': 552, '9180원': 553, '차트': 554, '0.49%': 555, '10200원': 556, '3%': 557, '5일': 558, '21일': 559, '15일': 560, 'e': 561, '연속': 562, '아': 563, '익': 564, '헌혈': 565, 'ip': 566, '장비': 567, '개편': 568, '힘': 569, '4000만원': 570, '전국': 571, '6000만원': 572, '쓰레기': 573, '조성': 574, '에서': 575, '키운다': 576, '만에': 577, '지역': 578, '리뷰': 579, '베스트': 580, '개인': 581, '돌아왔다': 582, '캐릭터': 583, '줄인다': 584, '검사': 585, '활동': 586, '’,': 587, '몰서': 588, '아이폰': 589, '업계': 590, 'kbo': 591, '퓨처스리그': 592, '모니터링': 593, '살펴본': 594, '조명': 595, '상': 596, '장사': 597, '전략': 598, '김기훈': 599, '포터': 600, '노벨': 601, 'pr': 602, '협회장': 603, '선출': 604, '비행기': 605, '체계': 606, '웹젠': 607, '무인': 608, 'pc': 609, '방': 610, '위례신도시': 611, '11일': 612, '2020년': 613, '3200억원': 614, '···': 615, '기조': 616, '시그널': 617, '전문': 618, '조직': 619, 'aai': 620, '신설': 621, '과학기술': 622, '정보통신부': 623, '국세청': 624, '공리': 625, '마쳐': 626, '동반성': 627, '실현': 628, '노후': 629, '설비': 630, '채': 631, \"…'\": 632, '러너': 633, '200억': 634, '유동성': 635, '확보': 636, '생태계': 637, '앞장': 638, '시너지': 639, '4천억': 640, '화상': 641, 'ceo': 642, '김용순': 643, '토털': 644, 'pnt': 645, '대응': 646, '의료': 647, '트': 648, '中': 649, '3265억원': 650, '3.1%': 651, '19%': 652, '편견': 653, '깬': 654, '자격': 655, '획득': 656, '확장': 657, '빠른': 658, '1분': 659, '528억원': 660, '7.5%': 661, '국제': 662, '기계': 663, '박람회': 664, '제조': 665, '사례': 666, '연매출': 667, '1조': 668, '120억': 669, '공군기지': 670, '3천': 671, '167억원': 672, '17%': 673, '마켓': 674, '인사이트': 675, '준비': 676, 'kst': 677, '레이스': 678, '시티': 679, '나루': 680, '씨': 681, '큐리': 682, '中企': 683, '을': 684, '플렉스': 685, 'sw': 686, '계약서': 687, '늑장': 688, '발급': 689, '필리핀': 690, '마닐라': 691, '시청': 692, '소독': 693, '꼬인': 694, '실': 695, '타래': 696, '푼다': 697, '교통': 698, '전동차': 699, '영광': 700, '자율': 701, '주행': 702, '환경': 703, 'vs': 704, '정통부': 705, '갈등': 706, '심화': 707, 'prnewswire': 708, '128': 709, '테크놀로지': 710, '채택': 711, '90억': 712, '공군': 713, '21': 714, '정기': 715, '4000억': 716, '뿌리는': 717, '사멸': 718, '입증': 719, '이슈': 720, '왜': 721, '두고': 722, '충돌': 723, '했나': 724, '회사': 725, '번째': 726, '앞장서는': 727, '경기': 728, '수원시': 729, '임원': 730, '조직개편': 731, '단행': 732, '세종': 733, '38억': 734, '521%': 735, '][': 736, 'company': 737, 'watch': 738, '복귀': 739, '자신감': 740, '특징': 741, '어닝': 742, '서프라이즈': 743, '예상': 744, '네이처': 745, '셀': 746, '신도리코': 747, '에이': 748, '켐텍': 749, '뉴스룸': 750, '業': 751, '고용': 752, '늘렸다': 753, '1년': 754, '500': 755, '명': 756, 'soc': 757, '택배': 758, '물류': 759, '센터': 760, '후': 761, '문의': 762, '산업': 763, '삼성': 764, '전자': 765, '일상': 766, '잡는': 767, '큐브': 768, '피아': 769, 'khc': 770, '소개': 771, '박효': 772, 'icbm': 773, '력': 774, '을지대': 775, '캠퍼스': 776, '구현': 777, '매니': 778, '지드': 779, 'wan': 780, '창립': 781, '주년': 782, '기념': 783, '설명': 784, '회': 785, '숨은': 786, '혜주': 787, '액': 788, '20%': 789, '강소기업': 790, '자릿수': 791, '㈜': 792, '공주': 793, '1000만원': 794, '상당': 795, '물품': 796, '기탁': 797, '허브': 798, '공개': 799, '키워': 800, '박차': 801, '소형': 802, '0': 803, '봇물': 804, '불구': 805, '하고': 806, '활기': 807, '소득': 808, '솔로': 809, '영': 810, '앤': 811, '리치': 812, '배후': 813, '따라': 814, '양극화': 815, '걸어서': 816, '천장': 817, '높이': 818, '설계': 819, '반': 820, '사익': 821, '할': 822, '단지': 823, '경쟁': 824, '치열': 825, '통장': 826, '필요없는': 827, '강세': 828, '284억': 829, '가점': 830, '낮은': 831, '드라마': 832, '끝났지만': 833, '펜트하우스': 834, '인기': 835, '여전': 836, '360': 837, '인테리어': 838, '가뭄': 839, 'now': 840, '전문직': 841, '32억': 842, '10.65%': 843, '식약처': 844, '핑크': 845, '퐁': 846, '아기': 847, '상어': 848, '알린다': 849, '0.81%': 850, '카드': 851, '밴으로부터': 852, '인도': 853, '제기': 854, '1.19%': 855, '14.15%': 856, 'ce': 857, 'ivd': 858, '인증': 859, '최고급': 860, '브랜드': 861, '줄어드는데': 862, '아람': 863, '하이엔드': 864, '전성': 865, '10억': 866, '속속': 867, '등장': 868, '1.32%': 869, '家': 870, '장녀': 871, '임세령': 872, '청담동': 873, '사랑': 874, '400억': 875, '재력': 876, '과시': 877, '10.44%': 878, '7.01%': 879, '79%': 880, '휘청': 881, '신규': 882, '감소': 883, '호텔': 884, '쇼': 885, '자재': 886, '관': 887, '참가': 888, '18.82%': 889, '1.45%': 890, '고가': 891, '3.15%': 892, '청구권': 893, '행사': 894, '신주': 895, '85만': 896, '1.08%': 897, '단기간': 898, '골든': 899, '크로스': 900, '형성': 901, '단기': 902, '중기': 903, '이평': 904, '정': 905, '배열': 906, '美': 907, '업체': 908, 'hd': 909, '메': 910, '디스': 911, '완료': 912, '항균': 913, '미세': 914, '전류': 915, '8.54%': 916, '8.13%': 917, '6.89%': 918, '4.10%': 919, '10.14%': 920, '17.52%': 921, '9.59%': 922, '9.79%': 923, '4.91%': 924, '최고': 925, '전세': 926, '가는': 927, '?…': 928, '리츠': 929, '빌': 930, '마크': 931, '힐스': 932, '40억': 933, '센트럴': 934, '파크': 935, '해링턴': 936, '스퀘어': 937, '낙찰': 938, '8.99%': 939, '8.49%': 940, '401만': 941, '가능': 942, '바람': 943, '덮': 944, '칠라': 945, '비': 946, '10.64%': 947, '제조업체': 948, '무궁화': 949, '뜨는': 950, '모델링': 951, '수익': 952, '개선': 953, '이룰까': 954, '7.59%': 955, '5000억': 956, '나주': 957, '신축': 958, '착수': 959, '공시': 960, '500만': 961, '분율': 962, '32%': 963, '블루': 964, '모나코': 965, '대부': 966, '142억원': 967, '부당이득': 968, '금': 969, '10.28%': 970, '멕시코': 971, 'indre': 972, '기전': 973, '..,': 974, '또는': 975, '소각': 976, '수익권': 977, '양수': 978, '철회': 979, '300억원': 980, '채무': 981, '보증': 982, '토지': 983, '대금': 984, '전액': 985, '수령': 986, '5.25%': 987, '9.84%': 988, '90억원': 989, '미': 990, 'ht': 991, ')’': 992, '선포': 993, '상호': 994, '350원': 995, '배당률': 996, '4.3%': 997, '노벨경제학상': 998, '경매': 999, '이론': 1000, '근간': 1001, '제시': 1002, '급등': 1003, '13%': 1004, '52': 1005, '신고': 1006, '28억': 1007, '쏜다': 1008, '율': 1009, '4.36%': 1010, '300원': 1011, '11.21%': 1012, '미국': 1013, '연방': 1014, '화웨이': 1015, 'zte': 1016, '위협': 1017, '지정': 1018, '2.51%': 1019, '1.14%': 1020, '6.57%': 1021, '7.64%': 1022, '4.77%': 1023, '9.73%': 1024, '1.31%': 1025, '6%': 1026, '10,200원': 1027, '제어기': 1028, '차량': 1029, '0.58%': 1030, '오르며': 1031, '039010': 1032, '13.3%': 1033, '19일': 1034, 'etri': 1035, '거리': 1036, '무선': 1037, '우수': 1038, '웹사이트': 1039, '시상식': 1040, '2019': 1041, '웹': 1042, '어워드': 1043, '코리아': 1044, '연동': 1045, '9980원': 1046, '9780원': 1047, '30일': 1048, '9210원': 1049, '추천': 1050, '1.00%': 1051, '1.46%': 1052, '9920원': 1053, '플러스': 1054, '14일': 1055, '23일': 1056, '9230원': 1057, '1.60%': 1058, '2일': 1059, '7일': 1060, '9470원': 1061, '1.06%': 1062, '9500원': 1063, '11,300원': 1064, '창': 1065, '12,050원': 1066, '모집': 1067, '13,850원': 1068, '캡': 1069, '입주': 1070, '몰리': 1071, '웃는': 1072, '주식시장': 1073, '0.97%': 1074, '20억원': 1075, '매도': 1076, '외인': 1077, '팔': 1078, '9130원': 1079, '0.95%': 1080, '105억': 1081, '47.8%': 1082, '↓': 1083, '12,700원': 1084, '31일': 1085, '9610원': 1086, '2.44%': 1087, '10,950원': 1088, '12,900원': 1089, '10000원': 1090, '8860원': 1091, '보기': 1092, '9400원': 1093, '9730원': 1094, '코': 1095, '맥스': 1096, '2025년': 1097, '5천억원': 1098, '천명': 1099, '캠페인': 1100, '백신': 1101, '접종': 1102, '키': 1103, '배기': 1104, '지배구조': 1105, '임박': 1106, '하이닉스': 1107, '&': 1108, 'a': 1109, '보폭': 1110, '커지나': 1111, '모바일': 1112, '엣지': 1113, '컴퓨팅': 1114, '지니': 1115, '뮤직': 1116, '페이스북': 1117, '릴레이': 1118, '모은다': 1119, '벤처기업': 1120, '1.6억원': 1121, '억대': 1122, '일회용품': 1123, '줄인': 1124, '상금': 1125, '커넥티드카': 1126, '모빌리티': 1127, '먹거리': 1128, '뱅크': 1129, '샐러드': 1130, '250억원': 1131, '파이': 1132, '낸스': 1133, '진영': 1134, '꾸린다': 1135, '철퇴': 1136, '즐기고': 1137, '줄': 1138, '이고': 1139, '선봬': 1140, '줄이는': 1141, 'mz': 1142, '소통': 1143, '전용': 1144, '론칭': 1145, '걸고': 1146, '찾는다': 1147, '...\"': 1148, '감시': 1149, '피': 1150, '하려': 1151, '임의': 1152, '조절': 1153, '찾습니다': 1154, '선발': 1155, '딴': 1156, '쿠': 1157, '바스': 1158, '합류': 1159, '안정감': 1160, '더한다': 1161, '대리점': 1162, '몰랐다': 1163, '호소': 1164, '깎아': 1165, '준': 1166, '수집': 1167, '가입자': 1168, '6500만원': 1169, '친환경': 1170, '가치': 1171, '소비': 1172, '1.64억': 1173, '혐의': 1174, '받아': 1175, '강백호': 1176, '찬스': 1177, '삼진': 1178, '중소기업': 1179, '안전하게': 1180, '지코': 1181, '콘텐츠': 1182, '엔진': 1183, '가동': 1184, '916일': 1185, '감격': 1186, '승리': 1187, '팀': 1188, '맹': 1189, '추격': 1190, '뿌리': 1191, '치고': 1192, '수렁': 1193, 'mk': 1194, 'regulator': 1195, 'fine': 1196, '1.6억': 1197, '허수': 1198, '반복': 1199, '안전': 1200, '…`': 1201, '친': 1202, '잘나가게': 1203, '예비': 1204, '창업': 1205, '상권': 1206, '손잡고': 1207, '지주': 1208, '인적': 1209, '분할': 1210, '번': 1211, '기변': 1212, '차별': 1213, '계': 1214, '방위': 1215, '혁신': 1216, '★': 1217, '잠실': 1218, '8-7': 1219, '진땀': 1220, '배정': 1221, '방망이': 1222, '부러져도': 1223, '안타': 1224, '집결': 1225, '알티': 1226, '오프라인': 1227, '입어': 1228, 'is': 1229, '잡고': 1230, '만루홈런': 1231, '통산': 1232, '150': 1233, '6499만': 1234, '돌아온': 1235, '18년': 1236, '부활': 1237, \"'...\": 1238, '클릭': 1239, '사상': 1240, '1': 1241, '兆': 1242, '향': 1243, '해': 1244, '순항': 1245, '마이크로소프트': 1246, '선정': 1247, '20년': 1248, '마스코트': 1249, '‧': 1250, '격차': 1251, '위험': 1252, '알려주는': 1253, '선보인다': 1254, '직접': 1255, '방법': 1256, '미리': 1257, '알려': 1258, '준다': 1259, '어떤': 1260, '돌': 1261, '보미': 1262, '자처': 1263, '자사': 1264, '자녀': 1265, '\",': 1266, '유전자': 1267, '몰에서': 1268, '초등생': 1269, '태블릿': 1270, '원격': 1271, '점검': 1272, '집중': 1273, '자가': 1274, '연': 1275, '다': 1276, '만든다': 1277, '시행': 1278, '철수': 1279, '쓸': 1280, '있다': 1281, '단말기': 1282, '판다': 1283, '\\'…\"': 1284, '용량': 1285, '쓰게': 1286, '될까': 1287, 'ios': 1288, '앱': 1289, '검토': 1290, 'shop': 1291, \")',\": 1292, '인터넷': 1293, '가입': 1294, '혜택': 1295, '풍': 1296, '성한': 1297, '비교': 1298, '사이트': 1299, '방문자': 1300, '몰려': 1301, '타이틀': 1302, '스폰서': 1303, '포탈': 1304, '웍스': 1305, '전면': 1306, '함께': 1307, '뛴다': 1308, '연간': 1309, '4500만': 1310, 'kwh': 1311, '아낀다': 1312, '디즈니': 1313, '상륙': 1314, '분주': 1315, '황현': 1316, '식': 1317, '개': 1318, '국사': 1319}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vQkTfhNPlYU"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Y6V2v4HkPqHG",
        "outputId": "4b1d3aaf-257e-4ba1-f17d-75fe7b315cfd"
      },
      "source": [
        "plt.hist([len(x) for x in X_train], bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 248,
              "width": 369
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utt82806QIOT"
      },
      "source": [
        "max_len = 25\n",
        "X_train = pad_sequences(X_train, maxlen = max_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGXab8ARQneu"
      },
      "source": [
        "***Label Encoding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvFh8Kk4QiDT",
        "outputId": "00954189-e3e6-41c1-e37e-4ad9faf85b80"
      },
      "source": [
        "idx_encode = preprocessing.LabelEncoder()\n",
        "idx_encode.fit(df_intent['intent'])\n",
        "\n",
        "y_train = idx_encode.transform(df_intent['intent'])\n",
        "\n",
        "label_idx = dict(zip(list(idx_encode.classes_), idx_encode.transform(list(idx_encode.classes_))))\n",
        "print(label_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'기타': 0, '매출': 1, '사업확장': 2, '시장전망': 3, '전략': 4, '주식전망': 5, '홍보': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vj9AzeLQ9uQ"
      },
      "source": [
        "idx_label = {}\n",
        "for key, value in label_idx.items():\n",
        "    idx_label[value] = key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My4sa3MXRDKJ"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ_5dqhVRFq3",
        "outputId": "ae439268-338a-4c3f-e7fa-61117573fbae"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 64))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(label_idx), activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAez8S6_RL1n",
        "outputId": "33bae9dd-c5d7-4ffb-8807-8432fa8e40b7"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs = 100, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/100\n",
            "493/493 [==============================] - 2s 4ms/sample - loss: 1.8956 - acc: 0.2170\n",
            "Epoch 2/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 1.7492 - acc: 0.2860\n",
            "Epoch 3/100\n",
            "493/493 [==============================] - 0s 484us/sample - loss: 1.5329 - acc: 0.3996\n",
            "Epoch 4/100\n",
            "493/493 [==============================] - 0s 487us/sample - loss: 1.4098 - acc: 0.4239\n",
            "Epoch 5/100\n",
            "493/493 [==============================] - 0s 520us/sample - loss: 1.2846 - acc: 0.5030\n",
            "Epoch 6/100\n",
            "493/493 [==============================] - 0s 514us/sample - loss: 1.2346 - acc: 0.4767\n",
            "Epoch 7/100\n",
            "493/493 [==============================] - 0s 491us/sample - loss: 1.1446 - acc: 0.5761\n",
            "Epoch 8/100\n",
            "493/493 [==============================] - 0s 524us/sample - loss: 1.0174 - acc: 0.6369\n",
            "Epoch 9/100\n",
            "493/493 [==============================] - 0s 686us/sample - loss: 0.8840 - acc: 0.6755\n",
            "Epoch 10/100\n",
            "493/493 [==============================] - 0s 681us/sample - loss: 0.8560 - acc: 0.6491\n",
            "Epoch 11/100\n",
            "493/493 [==============================] - 0s 581us/sample - loss: 0.6791 - acc: 0.7465\n",
            "Epoch 12/100\n",
            "493/493 [==============================] - 0s 490us/sample - loss: 0.7452 - acc: 0.7120\n",
            "Epoch 13/100\n",
            "493/493 [==============================] - 0s 514us/sample - loss: 0.7455 - acc: 0.7404\n",
            "Epoch 14/100\n",
            "493/493 [==============================] - 0s 560us/sample - loss: 0.5004 - acc: 0.8377\n",
            "Epoch 15/100\n",
            "493/493 [==============================] - 0s 512us/sample - loss: 0.8541 - acc: 0.7688\n",
            "Epoch 16/100\n",
            "493/493 [==============================] - 0s 501us/sample - loss: 0.4854 - acc: 0.8276\n",
            "Epoch 17/100\n",
            "493/493 [==============================] - 0s 512us/sample - loss: 0.3119 - acc: 0.9067\n",
            "Epoch 18/100\n",
            "493/493 [==============================] - 0s 498us/sample - loss: 0.6646 - acc: 0.8296\n",
            "Epoch 19/100\n",
            "493/493 [==============================] - 0s 544us/sample - loss: 0.5069 - acc: 0.8479\n",
            "Epoch 20/100\n",
            "493/493 [==============================] - 0s 504us/sample - loss: 0.2135 - acc: 0.9554\n",
            "Epoch 21/100\n",
            "493/493 [==============================] - 0s 507us/sample - loss: 0.2125 - acc: 0.9412\n",
            "Epoch 22/100\n",
            "493/493 [==============================] - 0s 511us/sample - loss: 0.7796 - acc: 0.7890\n",
            "Epoch 23/100\n",
            "493/493 [==============================] - 0s 492us/sample - loss: 0.3203 - acc: 0.8966\n",
            "Epoch 24/100\n",
            "493/493 [==============================] - 0s 493us/sample - loss: 0.3100 - acc: 0.9087\n",
            "Epoch 25/100\n",
            "493/493 [==============================] - 0s 521us/sample - loss: 0.1669 - acc: 0.9594\n",
            "Epoch 26/100\n",
            "493/493 [==============================] - 0s 492us/sample - loss: 0.6539 - acc: 0.7809\n",
            "Epoch 27/100\n",
            "493/493 [==============================] - 0s 483us/sample - loss: 0.1316 - acc: 0.9736\n",
            "Epoch 28/100\n",
            "493/493 [==============================] - 0s 479us/sample - loss: 0.1611 - acc: 0.9533\n",
            "Epoch 29/100\n",
            "493/493 [==============================] - 0s 491us/sample - loss: 0.9574 - acc: 0.7140\n",
            "Epoch 30/100\n",
            "493/493 [==============================] - 0s 593us/sample - loss: 0.1170 - acc: 0.9777\n",
            "Epoch 31/100\n",
            "493/493 [==============================] - 0s 651us/sample - loss: 0.0829 - acc: 0.9817\n",
            "Epoch 32/100\n",
            "493/493 [==============================] - 0s 684us/sample - loss: 0.0819 - acc: 0.9817\n",
            "Epoch 33/100\n",
            "493/493 [==============================] - 0s 672us/sample - loss: 0.4486 - acc: 0.8519\n",
            "Epoch 34/100\n",
            "493/493 [==============================] - 0s 515us/sample - loss: 0.0971 - acc: 0.9736\n",
            "Epoch 35/100\n",
            "493/493 [==============================] - 0s 568us/sample - loss: 0.0735 - acc: 0.9838\n",
            "Epoch 36/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 0.0963 - acc: 0.9675\n",
            "Epoch 37/100\n",
            "493/493 [==============================] - 0s 580us/sample - loss: 0.7860 - acc: 0.7890\n",
            "Epoch 38/100\n",
            "493/493 [==============================] - 0s 617us/sample - loss: 0.0965 - acc: 0.9716\n",
            "Epoch 39/100\n",
            "493/493 [==============================] - 0s 532us/sample - loss: 0.0828 - acc: 0.9777\n",
            "Epoch 40/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 0.3201 - acc: 0.8966\n",
            "Epoch 41/100\n",
            "493/493 [==============================] - 0s 555us/sample - loss: 0.2230 - acc: 0.9290\n",
            "Epoch 42/100\n",
            "493/493 [==============================] - 0s 696us/sample - loss: 0.0687 - acc: 0.9797\n",
            "Epoch 43/100\n",
            "493/493 [==============================] - 0s 685us/sample - loss: 0.6910 - acc: 0.8073\n",
            "Epoch 44/100\n",
            "493/493 [==============================] - 0s 531us/sample - loss: 0.0727 - acc: 0.9878\n",
            "Epoch 45/100\n",
            "493/493 [==============================] - 0s 504us/sample - loss: 0.0485 - acc: 0.9899\n",
            "Epoch 46/100\n",
            "493/493 [==============================] - 0s 664us/sample - loss: 0.1602 - acc: 0.9594\n",
            "Epoch 47/100\n",
            "493/493 [==============================] - 0s 654us/sample - loss: 0.0544 - acc: 0.9838\n",
            "Epoch 48/100\n",
            "493/493 [==============================] - 0s 522us/sample - loss: 0.0632 - acc: 0.9777\n",
            "Epoch 49/100\n",
            "493/493 [==============================] - 0s 500us/sample - loss: 0.7949 - acc: 0.7809\n",
            "Epoch 50/100\n",
            "493/493 [==============================] - 0s 518us/sample - loss: 0.0508 - acc: 0.9878\n",
            "Epoch 51/100\n",
            "493/493 [==============================] - 0s 501us/sample - loss: 0.0326 - acc: 0.9919\n",
            "Epoch 52/100\n",
            "493/493 [==============================] - 0s 506us/sample - loss: 0.0375 - acc: 0.9817\n",
            "Epoch 53/100\n",
            "493/493 [==============================] - 0s 514us/sample - loss: 0.0738 - acc: 0.9757\n",
            "Epoch 54/100\n",
            "493/493 [==============================] - 0s 512us/sample - loss: 0.1534 - acc: 0.9635\n",
            "Epoch 55/100\n",
            "493/493 [==============================] - 0s 520us/sample - loss: 0.0345 - acc: 0.9899\n",
            "Epoch 56/100\n",
            "493/493 [==============================] - 0s 495us/sample - loss: 0.6285 - acc: 0.8195\n",
            "Epoch 57/100\n",
            "493/493 [==============================] - 0s 506us/sample - loss: 0.0835 - acc: 0.9797\n",
            "Epoch 58/100\n",
            "493/493 [==============================] - 0s 517us/sample - loss: 0.0423 - acc: 0.9899\n",
            "Epoch 59/100\n",
            "493/493 [==============================] - 0s 522us/sample - loss: 0.0316 - acc: 0.9919\n",
            "Epoch 60/100\n",
            "493/493 [==============================] - 0s 521us/sample - loss: 0.0222 - acc: 0.9959\n",
            "Epoch 61/100\n",
            "493/493 [==============================] - 0s 541us/sample - loss: 0.3477 - acc: 0.9229\n",
            "Epoch 62/100\n",
            "493/493 [==============================] - 0s 515us/sample - loss: 0.0326 - acc: 0.9919\n",
            "Epoch 63/100\n",
            "493/493 [==============================] - 0s 509us/sample - loss: 0.0360 - acc: 0.9878\n",
            "Epoch 64/100\n",
            "493/493 [==============================] - 0s 501us/sample - loss: 0.3081 - acc: 0.9168\n",
            "Epoch 65/100\n",
            "493/493 [==============================] - 0s 492us/sample - loss: 0.1436 - acc: 0.9533\n",
            "Epoch 66/100\n",
            "493/493 [==============================] - 0s 512us/sample - loss: 0.0336 - acc: 0.9939\n",
            "Epoch 67/100\n",
            "493/493 [==============================] - 0s 496us/sample - loss: 0.0264 - acc: 0.9939\n",
            "Epoch 68/100\n",
            "493/493 [==============================] - 0s 491us/sample - loss: 0.4186 - acc: 0.9026\n",
            "Epoch 69/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 0.0738 - acc: 0.9797\n",
            "Epoch 70/100\n",
            "493/493 [==============================] - 0s 511us/sample - loss: 0.2388 - acc: 0.9270\n",
            "Epoch 71/100\n",
            "493/493 [==============================] - 0s 500us/sample - loss: 0.0340 - acc: 0.9919\n",
            "Epoch 72/100\n",
            "493/493 [==============================] - 0s 506us/sample - loss: 0.0278 - acc: 0.9939\n",
            "Epoch 73/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 0.0215 - acc: 0.9939\n",
            "Epoch 74/100\n",
            "493/493 [==============================] - 0s 504us/sample - loss: 0.0247 - acc: 0.9959\n",
            "Epoch 75/100\n",
            "493/493 [==============================] - 0s 508us/sample - loss: 0.3217 - acc: 0.9310\n",
            "Epoch 76/100\n",
            "493/493 [==============================] - 0s 492us/sample - loss: 0.0490 - acc: 0.9777\n",
            "Epoch 77/100\n",
            "493/493 [==============================] - 0s 494us/sample - loss: 0.0384 - acc: 0.9858\n",
            "Epoch 78/100\n",
            "493/493 [==============================] - 0s 514us/sample - loss: 0.0311 - acc: 0.9878\n",
            "Epoch 79/100\n",
            "493/493 [==============================] - 0s 523us/sample - loss: 0.0170 - acc: 0.9959\n",
            "Epoch 80/100\n",
            "493/493 [==============================] - 0s 497us/sample - loss: 0.0753 - acc: 0.9817\n",
            "Epoch 81/100\n",
            "493/493 [==============================] - 0s 516us/sample - loss: 0.3738 - acc: 0.8763\n",
            "Epoch 82/100\n",
            "493/493 [==============================] - 0s 619us/sample - loss: 0.0704 - acc: 0.9777\n",
            "Epoch 83/100\n",
            "493/493 [==============================] - 0s 501us/sample - loss: 0.0273 - acc: 0.9939\n",
            "Epoch 84/100\n",
            "493/493 [==============================] - 0s 520us/sample - loss: 0.0233 - acc: 0.9939\n",
            "Epoch 85/100\n",
            "493/493 [==============================] - 0s 515us/sample - loss: 0.0193 - acc: 0.9939\n",
            "Epoch 86/100\n",
            "493/493 [==============================] - 0s 677us/sample - loss: 0.0179 - acc: 0.9959\n",
            "Epoch 87/100\n",
            "493/493 [==============================] - 0s 623us/sample - loss: 0.0341 - acc: 0.9878\n",
            "Epoch 88/100\n",
            "493/493 [==============================] - 0s 501us/sample - loss: 0.4213 - acc: 0.9189\n",
            "Epoch 89/100\n",
            "493/493 [==============================] - 0s 521us/sample - loss: 0.1142 - acc: 0.9736\n",
            "Epoch 90/100\n",
            "493/493 [==============================] - 0s 547us/sample - loss: 0.0235 - acc: 0.9939\n",
            "Epoch 91/100\n",
            "493/493 [==============================] - 0s 486us/sample - loss: 0.0168 - acc: 0.9939\n",
            "Epoch 92/100\n",
            "493/493 [==============================] - 0s 505us/sample - loss: 0.0324 - acc: 0.9899\n",
            "Epoch 93/100\n",
            "493/493 [==============================] - 0s 672us/sample - loss: 0.0232 - acc: 0.9939\n",
            "Epoch 94/100\n",
            "493/493 [==============================] - 0s 497us/sample - loss: 0.0689 - acc: 0.9777\n",
            "Epoch 95/100\n",
            "493/493 [==============================] - 0s 673us/sample - loss: 0.6192 - acc: 0.9047\n",
            "Epoch 96/100\n",
            "493/493 [==============================] - 0s 652us/sample - loss: 0.0205 - acc: 0.9939\n",
            "Epoch 97/100\n",
            "493/493 [==============================] - 0s 560us/sample - loss: 0.0154 - acc: 0.9959\n",
            "Epoch 98/100\n",
            "493/493 [==============================] - 0s 649us/sample - loss: 0.0123 - acc: 0.9980\n",
            "Epoch 99/100\n",
            "493/493 [==============================] - 0s 610us/sample - loss: 0.0113 - acc: 0.9980\n",
            "Epoch 100/100\n",
            "493/493 [==============================] - 0s 554us/sample - loss: 0.0128 - acc: 0.9980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f139a7a2d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2mLxpv8Rk26"
      },
      "source": [
        "def article_processing(sentences):\n",
        "    inputs = []\n",
        "    for sentence in sentences:\n",
        "        sentence = okt.morphs(sentence) \n",
        "        encoded = tokenizer.texts_to_sequences([sentence])\n",
        "        inputs.append(encoded[0])\n",
        "    padded_inputs = pad_sequences(inputs, maxlen=max_len, padding='post')\n",
        "    return padded_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnufUxnRRSMW"
      },
      "source": [
        "search_word = '현대통신'\n",
        "results = get_news(search_word, 10)\n",
        "\n",
        "input_sentence = article_processing(results['Title'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cpNI7OEZU2p7",
        "outputId": "36edec51-fc1d-4162-b25e-647b75acbd26"
      },
      "source": [
        "results.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Adress</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>현대통신, 20억 규모 자사주 취득 신탁계약 체결</td>\n",
              "      <td>http://www.heraldbiz.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>투자주식 현대통신 주가 8일 현재 9400원</td>\n",
              "      <td>http://nbntv.co.kr/news/view/461720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4월 3일 현대통신 증권주식 0.00% 10350원</td>\n",
              "      <td>http://www.nbntv.co.kr/news/articleView.html?i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>공정위, 아파트 마감재 입찰 담합 칼슨·현대통신·은광사 제재</td>\n",
              "      <td>http://www.koscaj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>주가차트 현대통신 주가 5일 현재 9730원</td>\n",
              "      <td>http://nbntv.co.kr/news/view/457368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Title                                             Adress\n",
              "95        현대통신, 20억 규모 자사주 취득 신탁계약 체결                          http://www.heraldbiz.com/\n",
              "96           투자주식 현대통신 주가 8일 현재 9400원                http://nbntv.co.kr/news/view/461720\n",
              "97       4월 3일 현대통신 증권주식 0.00% 10350원  http://www.nbntv.co.kr/news/articleView.html?i...\n",
              "98  공정위, 아파트 마감재 입찰 담합 칼슨·현대통신·은광사 제재                              http://www.koscaj.com\n",
              "99           주가차트 현대통신 주가 5일 현재 9730원                http://nbntv.co.kr/news/view/457368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me4Lw0IuSnEu",
        "outputId": "ff05d716-9ebd-4b59-aa3b-a11ca63fb82d"
      },
      "source": [
        "prediction = np.argmax(model.predict(input_sentence), axis=1)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 6 6 5 3 5 5 3 5 5 5 3 5 5 5 5 5 5 5 5 2 5 5 6 5 5 5 3 0 0 6 4 5 5 5 5 5\n",
            " 5 5 5 0 0 5 5 5 5 5 5 5 5 5 5 5 5 5 0 5 5 5 5 5 5 6 5 5 5 3 5 5 5 5 0 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 0 5 5 5 5 5 5 5 5 5 4 5 5 3 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8udTwKXTtTb"
      },
      "source": [
        "prediction_results = []\n",
        "for p in prediction:\n",
        "  prediction_results.append(idx_label[p])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqLWUSmT_WM"
      },
      "source": [
        "from collections import Counter\n",
        "class_rs = Counter(prediction_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJiD8qlUjNy",
        "outputId": "8014299b-c3d3-449e-a6ea-41edf8eefde8"
      },
      "source": [
        "class_rs.most_common(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('주식전망', 78)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRIbMbB1jM_0"
      },
      "source": [
        "# 답변 초안"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyaWecI3XPNY",
        "outputId": "f9699033-287a-4822-9325-64bc972644cd"
      },
      "source": [
        "idx_num = np.where(pd.DataFrame(prediction_results).iloc[:,0] == str(class_rs.most_common(1)[0][0]))[0].min()\n",
        "issue = class_rs.most_common(1)[0][0]\n",
        "recent_topic = results.iloc[idx_num,0]\n",
        "recent_link = results.iloc[idx_num,1]\n",
        "\n",
        "print(f'{search_word}에 대해 꼭 알아두셔야 할 핫이슈 키워드는 V{issue} 이고,') \n",
        "print(f'해당 이슈의 가장 최근 뉴스 \"{recent_topic}\"에대한 세부기사는 여기 -> {recent_link} 에서 확인할 수 있어요.')\n",
        "\n",
        "df_statement = crawling_financial_statement(search_word).replace(',','', regex=True)\n",
        "subst_rows = df_statement.iloc[:,2].astype('float64') - df_statement.iloc[:,1].astype('float64')  \n",
        "if sum(subst_rows < 0) > 0:\n",
        "  print(\"\")\n",
        "  print(f'어맛 어떠케해요! 이것도 꼭 알아두세요! {search_word}의 재무재표의 아래 항목들에서 최근 V감소 추세를 발견했어요')\n",
        "  print(\"\")\n",
        "  for i in range(len(np.where(subst_rows < 0)[0])):\n",
        "    print('  * ',subst_rows.index[np.where(subst_rows < 0)][i])\n",
        "  else:\n",
        "    print(\"\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "현대통신에 대해 꼭 알아두셔야 할 핫이슈 키워드는 V주식전망 이고,\n",
            "해당 이슈의 가장 최근 뉴스 \"[배당뉴스] 현대통신, 주당 350원 배당...시가배당률 4.3%\"에대한 세부기사는 여기 -> http://www.itooza.com/common/iview.php?no=2021031211082445208 에서 확인할 수 있어요.\n",
            "\n",
            "어맛 어떠케해요! 이것도 꼭 알아두세요! 현대통신의 재무재표의 아래 항목들에서 최근 V감소 추세를 발견했어요\n",
            "\n",
            "  *  매출액\n",
            "  *  영업이익\n",
            "  *  당기순이익\n",
            "  *  영업이익률\n",
            "  *  순이익률\n",
            "  *  ROE(지배주주)\n",
            "  *  부채비율\n",
            "  *  당좌비율\n",
            "  *  EPS(원)\n",
            "  *  PBR(배)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBctwWzrVeNP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_uhDR1ZOtzz"
      },
      "source": [
        "- 우선, 잡아본 질문 초안과, 답변 초안은 위와 같습니다.\n",
        "        * 투자정보에 대한 질문을 하면 최근 100 기사를 크롤링 및 기사에 대한 인텐트를 예측하고 예측한 정보 중 가장 빈도수가 많은 부류의 가장 최근의 기사를 요약하여 전달합니다.\n",
        "        * 더불어, 재무재표를 크롤링하여, 얻어낸 결과 중\n",
        "        가장 최근 년도의 항목들의 값과 이전 년도의 항목들의 값의 차(-)의 결과값이 음수이 경우가 1개 이상인 경우에만, \n",
        "        '어맛 어떠케해요! 이것도 꼭 알아두세요! 현대통신의 재무재표의 아래 항목들에서 최근 V감소 추세를 발견했어요' 라는 메세지와 함께 해당 항목들을 확인시켜줍니다.\n",
        "===============================================================================\n",
        "\n",
        "  - 추가적으로 거래량, 가격 의 '어제' '오늘' 의 값을 요구하는 경우 해당 질문을 분별하여 제시하기\n",
        "  - 거래량의 추세를 물어보는 경우, 선택 년도를 일력하라는 질문 후 Isolation Forest 혹은 SARIMA 를 통해 이상적인 값으 탐색하여 날짜와 함께 제시할 계획입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLcp9jEwlRt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVc3ZNQ14ghF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}